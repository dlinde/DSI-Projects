{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping and Classifying Indeed Job Postings for Data Occupations\n",
    "\n",
    "### Dimitri Linde / June 2017\n",
    "\n",
    "<img src=\"https://qph.ec.quoracdn.net/main-qimg-7d724d66f0524d63c71283eafa60b5e3\" style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Scraping HTML From Relevant Indeed Postings\n",
    "\n",
    "In order to test whether I can a) classify whether a job posting is a data science job or a job in some related field and b) distinguish high-wage jobs from lower wage jobs, I need to scrape job postings first. Below, I've written a function to, given a seed url, crawl the job aggregator www.indeed.com and parse the HTML on each page of postings to extract the urls that contain 'company,' a proxy that a posting is hosted at Indeed. All url's containing 'company are hosted on indeed but not all postings hosted on Indeed contain 'company.' Information on postings hosted on Indeed can, like searching for urls on Indeed, be parsed with a one-size fits all approach. I then append the Indeed postings containing 'company' to a list and, after removing the duplicate values, return the list once the 100 or fewer pages pertaining to the seed url have been crawled. There is also a print function, to let us know the crawl_indeed function has concluded as well as how many postings have been collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get posting urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl_indeed(link):\n",
    "    i = 0\n",
    "    indeed_postings = []\n",
    "    while i < 1000:\n",
    "        response = requests.get(link+str(i))\n",
    "        i +=10\n",
    "        HTML = response.text\n",
    "        tree = html.fromstring(HTML)\n",
    "        urls = tree.xpath('////div[@id]/h2[@id]/a[@class]/@href')\n",
    "        for url in urls:\n",
    "            if 'company' in url:\n",
    "                indeed_url = 'http://www.indeed.com'+url\n",
    "                indeed_postings.append(indeed_url)\n",
    "    indeed_postings = np.unique(indeed_postings)\n",
    "    print len(indeed_postings)\n",
    "    return indeed_postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50,000-75,000 Data Science, Data Analyst, Analytics, and Business Intelligence Jobs in Boston\n",
    "\n",
    "To get a mix of data science and related occupations, I use the following keywords: \n",
    "* 'data science' \n",
    "* 'data analyst' \n",
    "* 'analytics' \n",
    "* 'business intelligence' \n",
    "\n",
    "I also define three salary tiers:\n",
    "* 50,000 - 75,000\n",
    "* 85,000 - 110,000\n",
    "* 120,000+ (later revised down to 115K+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "66\n",
      "84\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "ds_50 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+science+%2450000-%2475000&l=Boston%2C+MA&start=\")\n",
    "da_50 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+analyst+%2450000-%2475000&l=Boston%2C+MA&start=\")\n",
    "analytics_50 = crawl_indeed(\"https://www.indeed.com/jobs?q=analytics+%2450000-%2475000&l=Boston%2C+MA&start=\")\n",
    "bi_50 = crawl_indeed(\"https://www.indeed.com/jobs?q=business+intelligence+%2450000-%2475000&l=Boston%2C+MA&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 85,000 -110,00 Data Science, Data Analyst, Analytics, and Business Intelligence Jobs in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "30\n",
      "58\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "ds_85 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+science+%2485000-%24110000&l=Boston%2C+MA&start=\")\n",
    "da_85 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+analyst+%2485000-%24110000&l=Boston%2C+MA&start=\")\n",
    "analytics_85 = crawl_indeed(\"https://www.indeed.com/jobs?q=analytics+%2485000-%24110000&l=Boston%2C+MA&start=\")\n",
    "bi_85 = crawl_indeed(\"https://www.indeed.com/jobs?q=business+intelligence+%2485000-%24110000&l=Boston%2C+MA&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 120,000+ Data Science, Data Analyst, Analytics, and Business Intelligence Jobs in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "18\n",
      "48\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "ds_120 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+science+%24120000&l=Boston%2C+MA&start=\")\n",
    "da_120 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+analyst+%24120000&l=Boston%2C+MA&start=\")\n",
    "analytics_120 = crawl_indeed(\"https://www.indeed.com/jobs?q=analytics+%24120000&l=Boston%2C+MA&start=\")\n",
    "bi_120 = crawl_indeed(\"https://www.indeed.com/jobs?q=business+intelligence+%24120000&l=Boston%2C+MA&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scientist Jobs in San Francisco\n",
    "\n",
    "It will turn out that, after determining which postings I'd consider data science jobs, very few of the postings acquired with the keywords above qualify. The \"data scientist\" keyword turns out to be a far better proxy for data science job postings than \"data science\", so I search for data scientist at the higher income tiers, where we have fewer postings. San Francisco and New York do not churn up enough postings to analyze alone, so I also search across the US. Duplicates will be removed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "dssf_115 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%24115%2C000&l=San+Francisco%2C+CA&start=\")\n",
    "dssf_80 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%2485000+-+%24110000&l=San+Francisco%2C+CA&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scientist Jobs in New York City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "dsny_115 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%24115000&l=New+York%2C+NY&start=\")\n",
    "dsny_80 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%2485000+-+%24110000&l=New+York%2C+NY&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scientist Jobs in the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "dsusa_115 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%24115000&l=United+States&start=\")\n",
    "dsusa_80 = crawl_indeed(\"https://www.indeed.com/jobs?q=data+scientist+%2485000+-+%24110000&l=United+States&start=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the arrays at the same income level and remove any duplicates\n",
    "\n",
    "This yields one array of postings at each income tier. Duplicates, between, for example, postings in the data science list and postings in the data scientist list, are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "data_50 = np.concatenate((ds_50,da_50,analytics_50,bi_50))\n",
    "data_50 = np.unique(data_50)\n",
    "print len(data_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "data_85 = np.concatenate((ds_85,da_85,analytics_85, bi_85, dssf_80,dsny_80,dsusa_80))\n",
    "data_85 = np.unique(data_85)\n",
    "print len(data_85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "data_120 = np.concatenate((ds_120,da_120,analytics_120,bi_120, dssf_115,dsny_115,dsusa_115))\n",
    "data_120 = np.unique(data_120)\n",
    "print len(data_120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe\n",
    "\n",
    "With the url's for relevant job postings that I've collected, I first want to put them into a dataframe. Once there, I want to iterate through the urls, extracting the HTML from that page and inserting it into the dataframe. Later, I'll use the HTML to extract information like job requirements and title, but which, once saved in a dataframe, I can access at any time. I'll also tag the postings with their income level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indeed_df(array, income_tier):\n",
    "    df = pd.DataFrame(array, columns=['url'])\n",
    "    for i in df.index:\n",
    "        response = requests.get(df['url'][i])\n",
    "        df.ix[i,'HTML'] = response.text\n",
    "    df['category'] = income_tier\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.indeed.com/company/2020/jobs/Market...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.indeed.com/company/AA-Search/jobs/M...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.indeed.com/company/ABACS/jobs/Behav...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.indeed.com/company/AGENCY-451/jobs/...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.indeed.com/company/AKRAYA/jobs/Juni...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.indeed.com/company/2020/jobs/Market...   \n",
       "1  http://www.indeed.com/company/AA-Search/jobs/M...   \n",
       "2  http://www.indeed.com/company/ABACS/jobs/Behav...   \n",
       "3  http://www.indeed.com/company/AGENCY-451/jobs/...   \n",
       "4  http://www.indeed.com/company/AKRAYA/jobs/Juni...   \n",
       "\n",
       "                                                HTML       category  \n",
       "0  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000  \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000  \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000  \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000  \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_50_df = indeed_df(data_50, '50,000-75,000')\n",
    "data_50_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.indeed.com/company/1988/jobs/Sybase...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.indeed.com/company/AA-Search/jobs/F...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.indeed.com/company/AFFOA/jobs/Deput...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.indeed.com/company/AGENCY-451/jobs/...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.indeed.com/company/AKRAYA/jobs/Busi...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.indeed.com/company/1988/jobs/Sybase...   \n",
       "1  http://www.indeed.com/company/AA-Search/jobs/F...   \n",
       "2  http://www.indeed.com/company/AFFOA/jobs/Deput...   \n",
       "3  http://www.indeed.com/company/AGENCY-451/jobs/...   \n",
       "4  http://www.indeed.com/company/AKRAYA/jobs/Busi...   \n",
       "\n",
       "                                                HTML        category  \n",
       "0  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000  \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000  \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000  \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000  \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_85_df = indeed_df(data_85, '85,000-110,000')\n",
    "data_85_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.indeed.com/company/%E5%B9%BF%E4%B8%...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>115,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.indeed.com/company/3sixtyHR/jobs/De...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>115,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.indeed.com/company/A-Priori-Investm...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>115,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.indeed.com/company/AA-Search/jobs/E...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>115,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.indeed.com/company/ACV-Auctions/job...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>115,000+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.indeed.com/company/%E5%B9%BF%E4%B8%...   \n",
       "1  http://www.indeed.com/company/3sixtyHR/jobs/De...   \n",
       "2  http://www.indeed.com/company/A-Priori-Investm...   \n",
       "3  http://www.indeed.com/company/AA-Search/jobs/E...   \n",
       "4  http://www.indeed.com/company/ACV-Auctions/job...   \n",
       "\n",
       "                                                HTML  category  \n",
       "0  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  115,000+  \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  115,000+  \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  115,000+  \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  115,000+  \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  115,000+  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_115_df = indeed_df(data_120, '115,000+')\n",
    "data_115_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the dataframes to get a master df\n",
    "\n",
    "Lastly, I take the dataframes for the separate income tiers and concatenate them into one dataframe. I check for duplicates just in case and remove them if they appear; in this case, they don't. Lastly, we expert this dataframe to a .csv so that we can upload what we need to analyze without having to scrape new postings each time. That took a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "641\n"
     ]
    }
   ],
   "source": [
    "frames = [data_50_df, data_85_df, data_115_df]\n",
    "all_postings = pd.concat(frames, ignore_index=True)\n",
    "print all_postings.shape[0]\n",
    "all_postings = all_postings.drop_duplicates()\n",
    "print all_postings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_postings.to_csv(\"./scraped_postings\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2: Parsing The HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped_postings = pd.read_csv(\"./scraped_postings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading our dataframe of job postings, I use a series of path expressions to parse the HTML. Each query works to extract fields of information from job descriptions hosted on Indeed, of which all postings in the dataframe are. Specifically, I extract the job title, company, requirements, and summary fields. The summary field encompasses the information from the three former fields as well as all other information in a posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>requirements</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.indeed.com/company/2020/jobs/Market...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "      <td>[Marketing Manager]</td>\n",
       "      <td>[2020 On-site]</td>\n",
       "      <td>['Run 2020’s marketing strategy and execution'...</td>\n",
       "      <td>['Are you a results-oriented B2B marketing pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.indeed.com/company/2020/jobs/Market...   \n",
       "\n",
       "                                                HTML       category  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000   \n",
       "\n",
       "             job_title         company  \\\n",
       "0  [Marketing Manager]  [2020 On-site]   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  ['Run 2020’s marketing strategy and execution'...   \n",
       "\n",
       "                                             summary  \n",
       "0  ['Are you a results-oriented B2B marketing pro...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,len(scraped_postings)):\n",
    "    HTML = scraped_postings['HTML'][i]\n",
    "    tree = html.fromstring(HTML)\n",
    "    scraped_postings.ix[i,'job_title'] = tree.xpath('//b[@class=\"jobtitle\"]/font/text()')\n",
    "    scraped_postings.ix[i,'company'] = tree.xpath('//td[1]/div/span[@class=\"company\"]/text()')\n",
    "    scraped_postings.ix[i,'requirements'] = str(tree.xpath('//span[@id=\"job_summary\"]/ul/li/text()'))\n",
    "    scraped_postings.ix[i,'summary'] = str(tree.xpath('//span[@id=\"job_summary\"]//text()'))\n",
    "scraped_postings.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of my aim here is to classify data science jobs from related jobs, and job postings don't come tagged as data science jobs or not, I subjectively develop criteria based on scanning the list of job titles in the dataframe. Because there are references to, for example, \"Hadoop\" and \"hadoop,\" I make all text lowercase. About 20% of job titles in the dataframe meet my criteria of being a data science job. The most common job title among these jobs is, not surprisingly, data scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>requirements</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.indeed.com/company/2020/jobs/market...</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "      <td>['marketing manager']</td>\n",
       "      <td>['2020 on-site']</td>\n",
       "      <td>['run 2020’s marketing strategy and execution'...</td>\n",
       "      <td>['are you a results-oriented b2b marketing pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.indeed.com/company/2020/jobs/market...   \n",
       "\n",
       "                                                HTML       category  \\\n",
       "0  <!doctype html>\\n<html lang=\"en\">\\n<head><titl...  50,000-75,000   \n",
       "\n",
       "               job_title           company  \\\n",
       "0  ['marketing manager']  ['2020 on-site']   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  ['run 2020’s marketing strategy and execution'...   \n",
       "\n",
       "                                             summary  \n",
       "0  ['are you a results-oriented b2b marketing pro...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_postings = scraped_postings.apply(lambda x: x.astype(str).str.lower())\n",
    "scraped_postings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = (scraped_postings['job_title'].str.contains('data scien'))| (\n",
    "    scraped_postings['job_title'].str.contains('big data')) |  (scraped_postings['job_title'].str.contains('machine')) | (\n",
    "    scraped_postings['job_title'].str.contains('model')) | (\n",
    "    scraped_postings['job_title'].str.contains('business analytics')) | (\n",
    "    scraped_postings['job_title'].str.contains('hadoop'))\n",
    "ds_jobs = scraped_postings[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped_postings['ds_job'] = 0\n",
    "for i in ds_jobs:\n",
    "    scraped_postings.ix[i,'ds_job'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>HTML</th>\n",
       "      <th>category</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>ds_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>http://www.indeed.com/company/genewiz,-inc/job...</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>85,000-110,000</td>\n",
       "      <td>['bioinformatics scientist']</td>\n",
       "      <td>['want to be part of a company whose goal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>http://www.indeed.com/company/ywca-boston/jobs...</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"en\"&gt;\\n&lt;head&gt;&lt;titl...</td>\n",
       "      <td>50,000-75,000</td>\n",
       "      <td>['communications and marketing manager']</td>\n",
       "      <td>['general statement of duties', 'the manager o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "294  http://www.indeed.com/company/genewiz,-inc/job...   \n",
       "192  http://www.indeed.com/company/ywca-boston/jobs...   \n",
       "\n",
       "                                                  HTML        category  \\\n",
       "294  <!doctype html>\\n<html lang=\"en\">\\n<head><titl...  85,000-110,000   \n",
       "192  <!doctype html>\\n<html lang=\"en\">\\n<head><titl...   50,000-75,000   \n",
       "\n",
       "                                    job_title  \\\n",
       "294              ['bioinformatics scientist']   \n",
       "192  ['communications and marketing manager']   \n",
       "\n",
       "                                               summary  ds_job  \n",
       "294  ['want to be part of a company whose goal is t...       0  \n",
       "192  ['general statement of duties', 'the manager o...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = scraped_postings[['url','HTML','category','job_title','summary','ds_job']]\n",
    "subset = subset.sample(n=2)\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "79\n",
      "['data scientist']                                30\n",
      "['machine learning engineer']                      5\n",
      "['senior data scientist']                          5\n",
      "['big data engineer']                              2\n",
      "['principal data scientist']                       2\n",
      "['data scientist – machine learning – boston']     1\n",
      "['data architect / data modeler (pf)']             1\n",
      "['data science lead']                              1\n",
      "['data scientist, phd']                            1\n",
      "['data scientist-local candidates only']           1\n",
      "Name: job_title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mask = scraped_postings['ds_job']==1\n",
    "ds_titles = scraped_postings[mask]['job_title']\n",
    "print(len(ds_titles))\n",
    "print(ds_titles.nunique())\n",
    "print(ds_titles.value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Classifying Job Postings by Income-Level and Occupation-Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "For anyone who would like to replicate this: you will need to download the nltk stopwords corpus before being able to use them and you can find simple instructions for how to do so here:\n",
    "http://blog.nlpapi.co/how-to-install-nltk-corporastopwords/. I will expand on the list of stopwords to remove recurring character fragments as well as generic words in the posting summaries. Lastly, I will remove the 'u'' characters commonly preceding words parsed from HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = stopwords.words('english')\n",
    "english[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_to_stop = ['xe2', 'x80', 'x99s', 'xc2', 'xb7', 'xef', 'x82', 'x99', 'x93', 'x99ll', 'x9d', 'xac', 'x84',\n",
    "               'xa2','xc3']\n",
    "english = english + add_to_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scraped_postings['summary'] = scraped_postings['summary'].str.replace(\"u'\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a Snapshot of The Sample\n",
    "\n",
    "The following function will take in the summary column from the dataframe of parsed postings and return a sorted array of either the most frequent words or the highest term weights, depending on our choice of vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq_words(sparse_counts, columns):\n",
    "    # X_all is a sparse matrix, so sum() returns a 'matrix' datatype ...\n",
    "    #   which we then convert into a 1-D ndarray for sorting\n",
    "    word_counts = np.asarray(X_all.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    # argsort() returns smallest first, so we reverse the result\n",
    "    largest_count_indices = word_counts.argsort()[::-1]\n",
    "    freq_words = pd.Series(word_counts[largest_count_indices], \n",
    "                           index=columns[largest_count_indices])\n",
    "\n",
    "    return freq_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of most commonly occuring words across the 600+ job postings in the dataframe are largely generic though the frequency of \"data\" offers a hint that these postings differ from general business opporunities. The same is true of the most common n-grams, excepting, of course, machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           2467\n",
       "skills         1218\n",
       "development    1063\n",
       "team           1013\n",
       "management      867\n",
       "ability         854\n",
       "time            814\n",
       "strong          736\n",
       "analysis        714\n",
       "support         705\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most common words, all postings\n",
    "cvt      =  CountVectorizer(strip_accents='unicode', ngram_range=(1,1), stop_words=english, min_df=5)\n",
    "X_all    =  cvt.fit_transform(scraped_postings['summary'])\n",
    "columns  =  np.array(cvt.get_feature_names()) \n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full time               555\n",
       "type full time          504\n",
       "type full               504\n",
       "machine learning        306\n",
       "education bachelor      291\n",
       "communication skills    252\n",
       "computer science        206\n",
       "000 00                  180\n",
       "bachelor degree         179\n",
       "time education          170\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most common ngrams, all postings\n",
    "cvt = CountVectorizer(stop_words=english, ngram_range=(2,4))\n",
    "X_all = cvt.fit_transform(scraped_postings['summary'])\n",
    "columns  =  np.array(cvt.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking across the postings, the term weights don't tell us much more than the counts - the yield is still largely general business in nature. Marketing does make an appearance in this list, notable next to the other terms for being either a specific job function or department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           38.679487\n",
       "development    20.318091\n",
       "skills         19.813484\n",
       "marketing      17.813866\n",
       "team           17.633620\n",
       "analysis       16.456983\n",
       "management     16.433427\n",
       "ability        15.924655\n",
       "learning       15.812633\n",
       "software       14.761406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest tfidf, all postings\n",
    "tfidf = TfidfVectorizer(stop_words=english)\n",
    "X_all = tfidf.fit_transform(scraped_postings['summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll preemptively ignore some generic recurring business terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_to_stop = ['experience','business','required','work','years','job','project']\n",
    "english = english + add_to_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "I use topic modeling, also known as Latent Dirichlet Allocation, as an unsupervised method to ascertain the topics of the content in the job summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641, 3137)\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = english,\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 5)\n",
    "dtm = tf_vectorizer.fit_transform(scraped_postings['summary'])\n",
    "print(dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=7, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf = LatentDirichletAllocation(n_topics=7)\n",
    "lda_tf.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the pyLDAvis tool to visualize different numbers of topics and chose 7 after observing clear distinctions.\n",
    "\n",
    "Within each topic I can see the proportion of each word assigned to a topic (about 40% of the occurences of 'analysis' occur in topic 3), the salience of a given word within each topic ('analysis' occurs more frequently than any other term in topic 3), as well as the proportion of overall words in the document term matrix assigned to each topic (topic 3 includes 15.7% of the words in the document term matrix).\n",
    "\n",
    "Assigning names to topics is subjective but the relevant terms are a useful guide:\n",
    "* Topic 1 suggests both marketing analytics as well as client services (client, support, research, analysis)\n",
    "* Topic 2 has an operations/regulatory component, perhaps largely in medical settings (clinical, scientific, health)\n",
    "* Topic 3 is data science/machine learning oriented (machine, learning, software, engineering, python, statistics, statistical, algorithms)\n",
    "* Topic 4 reads as data engineering focused (informatica, etl, oracle, sql, warehousing, aggregate)\n",
    "* Topic 5, combining laboratory science with manufacturing terms, could be labeled 'biotech'\n",
    "\n",
    "Topics 6&7 only represent 0.5% of tokens in the document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el138346689721522745953586\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el138346689721522745953586_data = {\"mdsDat\": {\"Freq\": [41.30048009853539, 27.811511724168746, 15.698070449681223, 11.715420039950939, 2.9716120552593916, 0.41213023428854, 0.09077539811576284], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"x\": [0.008187567077621354, -0.05210580613311466, 0.10388247116597048, 0.2285724469404545, -0.0999354902594428, -0.10635254657214645, -0.08224864221934242], \"y\": [0.09690165283641, -0.012516626106006555, -0.042955926218989096, -0.0073503639628420755, -0.19047582524000703, 0.06119199597392977, 0.09520509271750491]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"Freq\": [361.0, 378.0, 362.0, 271.0, 278.0, 619.0, 446.0, 472.0, 236.0, 450.0, 306.0, 203.0, 497.0, 492.0, 338.0, 89.0, 230.0, 529.0, 365.0, 495.0, 473.0, 302.0, 205.0, 570.0, 461.0, 391.0, 122.0, 172.0, 431.0, 742.0, 178.05170336755242, 109.31300166895217, 50.43337314296104, 54.39904579372058, 130.2105495093447, 73.28069490952329, 55.92000134922829, 553.8751134286033, 118.2742704672883, 55.6311910498187, 22.62564904796964, 59.76357414987293, 21.148268505249224, 104.02518618666181, 121.57763511564686, 22.039223941177465, 27.357799724361616, 20.29839735606901, 19.900619140734683, 19.892586249632558, 18.392634816736248, 18.382167353909598, 19.041485537032745, 18.603990583814863, 15.977661980841054, 21.994962384640555, 80.93463395896369, 16.04834238049941, 19.30380656129423, 19.65003827358112, 30.239074468255165, 129.9439007800858, 82.75070613321638, 30.93652014599211, 57.461180998149715, 31.866609641709335, 393.93895095518803, 89.84923423628942, 75.03357358671047, 87.75327492490116, 35.485708533571675, 70.26292169074571, 47.29616418557181, 61.365698771361174, 239.49619064809343, 104.25307302926664, 198.90590580955765, 107.31026664738089, 80.59527109490766, 74.98755577364025, 330.40762811437986, 114.99914596304185, 108.74125230105587, 129.79766662115554, 353.0919445246051, 309.0446431245799, 167.8594175207017, 146.34804513373405, 199.19997775018314, 141.57876362831158, 120.84228648066998, 185.00309779147568, 325.72475607318614, 149.172145421255, 198.35365193876754, 141.1870856531058, 228.29968658812274, 205.51117194240524, 187.36025734728182, 188.41976711494402, 228.33488241995795, 142.65057857705767, 179.18172191866168, 175.7743757770941, 168.36653067598877, 203.19795417929245, 196.3084526318801, 214.80664223367137, 172.47101085533225, 170.35571121659183, 155.52862080332477, 152.02792577227157, 164.62710368312494, 154.15586940247124, 470.343195449799, 77.0509174654976, 151.5273173032632, 62.75745446292894, 90.93392567043878, 52.32682355320094, 39.515810957507284, 32.43100750547551, 27.57592404283087, 27.490905380625737, 43.96999571183816, 27.310484374465055, 28.19713118695841, 25.071306875851317, 23.47662151731666, 45.95298397673915, 22.526324206471156, 25.006104945626607, 21.992338495806962, 56.64592748439369, 22.02129070012256, 22.222813237537174, 20.072560528485624, 28.559666778522764, 21.15250737467705, 20.640023592876023, 18.08372096211869, 18.000988832624028, 18.08873198542006, 18.668121115829766, 93.37478938556508, 152.61417742356534, 77.81071934098745, 90.63492612269276, 60.93676191776846, 77.41420598872756, 79.14693270139298, 126.20790772588565, 112.37860626292532, 80.72173989217477, 72.78124786348239, 62.49368552008319, 89.49200793777514, 49.83702067965406, 167.9043109948419, 173.72939176370795, 145.8772369360882, 189.57631053192668, 110.03995045078388, 299.2881258650232, 77.64781185794016, 98.49388953634481, 138.86887350913634, 112.62040118878643, 135.55101096904423, 142.8494081878208, 222.2967888295759, 132.60654139703172, 136.28552427524204, 158.4055845784331, 157.6427885434198, 171.62814654407245, 159.6650582646267, 195.1465103370515, 121.71707749114769, 138.35053776231237, 132.82250680031012, 124.53210533815614, 141.15986372180512, 119.9042989110839, 123.58754497789468, 124.4269116313236, 127.91339406201675, 119.47447004416999, 26.972437905656832, 51.81625935885526, 20.385114530159132, 65.71384543034321, 25.378075040234283, 27.09664660132594, 17.44728123319977, 12.491679965738882, 33.72899139843264, 20.579529126989524, 9.287367803991245, 7.080827599606968, 18.97334087274275, 7.176505007699029, 8.843356464549418, 7.1184559289875455, 6.701449469171364, 17.688952051144277, 7.375761368467096, 13.613596704641461, 8.87226978358344, 8.048267925128176, 7.123922731220658, 52.14791938084309, 6.924264507336692, 6.133430791612095, 51.335905891710425, 33.077545007749734, 5.849695674304057, 11.957736632308025, 48.49442412797422, 142.0646718796751, 116.70924357991949, 39.51128285310441, 32.54012832733238, 16.008111023696205, 17.8824461108527, 26.674174528422935, 12.97652966106662, 78.38923805877913, 194.3143148272548, 251.98543399392736, 195.45139653631705, 29.62843254086977, 19.593597504550704, 296.47619489240964, 91.55947071068319, 36.659788349538026, 53.835383877429024, 46.35643348774341, 224.98234315182617, 203.1243502143097, 132.0763364741077, 308.7888723232537, 71.17168561844667, 103.89531240352878, 63.69532066711735, 133.15176974061524, 122.28209000141271, 174.23705501324443, 121.6243643708627, 89.20630057265336, 114.33940276390423, 149.70873268316876, 111.2604424905043, 82.95507427646592, 102.59609421629968, 87.4512946632322, 95.34725504956172, 113.00251693604345, 123.91947892252583, 86.7123748601753, 111.92796791948942, 94.8000930604606, 98.35508737602174, 103.1351755653914, 102.4077951977619, 90.13846114912052, 90.17449408633333, 360.61260831930826, 103.60052320230115, 107.39608874123896, 128.37157814573143, 56.349039954856416, 53.35312166942227, 226.80816689032648, 53.196787973800994, 200.10319324411572, 161.10794666354184, 31.799127431247104, 51.91033830199309, 56.48031415703097, 53.121788044299244, 53.78403244786272, 106.45135451810063, 52.74175239776433, 123.10388528283765, 54.67911745891655, 24.92435394982362, 55.65599309135842, 69.50136798591383, 13.750263329532231, 103.19661972933166, 53.55850906672273, 11.21690804773169, 59.91089735566069, 55.18873013376834, 10.867827328796697, 55.79612595608032, 53.046233324245726, 52.39407899006558, 113.30390486495999, 110.01824795697422, 315.2203388155708, 71.72848517394519, 65.78563929951522, 178.23045884856785, 216.1057926606992, 82.97556040353834, 270.77604387652815, 214.27190960362967, 158.82324620797112, 140.38044197797197, 90.6196334449987, 106.01267240953113, 206.43794845794608, 197.33973875273313, 131.50403003691093, 131.74012913851743, 133.72856948037773, 89.54552455893942, 113.22829367292317, 100.56483478276817, 102.50435183651338, 96.55091289049345, 91.66432020984026, 22.750123254001128, 18.455255154193196, 10.493284245265121, 10.876173749997424, 7.945478686559836, 13.561745345603448, 5.80370500114389, 29.820506242060834, 8.034810119613226, 22.943366647224757, 4.890604297977751, 9.617676436002457, 55.896210640879175, 9.302520171716239, 9.274623292508231, 7.80463728069935, 5.326283634525722, 8.672668002848683, 3.709893250531418, 9.601390151747047, 9.268944735029415, 4.659141500629132, 3.887375437835205, 27.119588980872265, 4.765457682864461, 54.38633386559988, 2.8328939937229327, 12.352417580456988, 7.926083806570265, 16.49564745371763, 55.062184373996246, 16.862051724783548, 103.3664533551002, 14.633231084580945, 47.441620420834106, 19.13920143472108, 36.12153293748226, 82.4481298139588, 27.249553103281645, 60.995465699688914, 32.992824685325395, 20.619913670515317, 18.86389207599981, 36.19816588960036, 13.701849218691821, 27.983913063706016, 35.10393838789571, 15.934423260660253, 25.76819841917833, 30.89889303103684, 28.158130658771906, 20.312875379493704, 26.9772413965202, 25.608168209590925, 23.741619769567716, 21.94171344107395, 20.517080595133343, 19.903890294866994, 18.86643331801282, 2.0478551610375115, 1.0740393215249968, 1.075276056402808, 1.5627324070550637, 6.747398533056867, 3.54260941068582, 1.0724616643566334, 2.0514304377989165, 1.0754970304326188, 2.048677894386118, 1.07267336298253, 2.3837095963973995, 1.0705917464133359, 1.5598788087569244, 1.0730896244316306, 1.0740255092698148, 1.9718696450057829, 1.0742775257960862, 1.0748453059252736, 1.0733230536680252, 1.5777047941164413, 1.0733489737392725, 1.5625994001844143, 0.7110387088954228, 1.0746809226005056, 2.037585761538085, 0.15922348285243335, 4.666344448207408, 1.0754073182242005, 1.5653243456222277, 1.4143749253023135, 2.045079148486182, 3.557385737456534, 3.9850135097127497, 6.235405513136009, 4.9132326547780165, 2.041170951106756, 4.796101581704945, 2.4077552628525343, 5.117411101778083, 2.045501356399964, 3.0163713454140093, 2.034384766486747, 2.2852360627318737, 3.5121906832496115, 2.127113440553388, 3.14167274459721, 2.658152644317151, 2.243763980884018, 2.0662495980394113, 2.150161817412329, 2.0476951905409293, 2.0629558393289704, 2.0596745560212515, 2.0525908573066536, 2.0488966066194054, 0.20073167401607742, 0.200533428757517, 0.3239958246024036, 0.31349191924778036, 0.2965681673247104, 0.16435565650686046, 0.1629599704934485, 0.15051820289381476, 0.14101914210019323, 0.15805093702179812, 0.19974878346125166, 0.1338612340748232, 0.18414332149756074, 0.11615613040648883, 0.134574247667732, 0.100149561037207, 1.3088177277023192, 0.1222539133330971, 0.09492055861772333, 0.12706392780491987, 0.45154947918156807, 0.03418762859309825, 0.033752362901427906, 0.08761120380743515, 0.03403020592495334, 0.03374588820890031, 0.03371224384360293, 0.03367474258234124, 0.0337813572881566, 0.03393058559188587, 0.07971763296962599, 0.07963575242143711, 0.10024111157385861, 0.09080110651640225, 0.08437825830096432, 0.15415925945514009, 0.08119460047709404, 0.07928845781325077, 0.1860588907792809, 0.16575222164092837, 0.1298200848843438, 0.11889911545854932, 0.0981198478753783, 0.14676605483321167, 0.13475843411693436, 0.1166345640337489], \"Term\": [\"informatica\", \"quality\", \"high\", \"within\", \"testing\", \"support\", \"plus\", \"clinical\", \"scientist\", \"position\", \"analytical\", \"able\", \"learning\", \"must\", \"sales\", \"compensation\", \"etl\", \"design\", \"machine\", \"technical\", \"systems\", \"candidate\", \"oracle\", \"marketing\", \"related\", \"understanding\", \"laboratory\", \"improve\", \"environment\", \"analysis\", \"digital\", \"campaigns\", \"advertising\", \"campaign\", \"media\", \"google\", \"school\", \"marketing\", \"content\", \"brand\", \"seo\", \"paid\", \"segmentation\", \"predictive\", \"social\", \"sem\", \"prospects\", \"ppc\", \"fundraising\", \"print\", \"million\", \"scikit\", \"reach\", \"curious\", \"survey\", \"display\", \"online\", \"kind\", \"carnegie\", \"generous\", \"outreach\", \"insights\", \"email\", \"things\", \"website\", \"options\", \"analytics\", \"search\", \"great\", \"consulting\", \"york\", \"passion\", \"interest\", \"cutting\", \"clients\", \"insurance\", \"looking\", \"learn\", \"like\", \"real\", \"client\", \"communications\", \"people\", \"opportunities\", \"new\", \"company\", \"help\", \"customers\", \"customer\", \"strategy\", \"market\", \"opportunity\", \"research\", \"build\", \"services\", \"manager\", \"position\", \"tools\", \"role\", \"product\", \"develop\", \"across\", \"solutions\", \"industry\", \"manage\", \"science\", \"learning\", \"analysis\", \"projects\", \"well\", \"based\", \"technology\", \"support\", \"high\", \"clinical\", \"trial\", \"study\", \"molecular\", \"accounting\", \"trials\", \"oncology\", \"biopharmaceutical\", \"toxicology\", \"ich\", \"pfizer\", \"gcp\", \"biotechnology\", \"genome\", \"investigator\", \"ngs\", \"disease\", \"genetics\", \"cro\", \"cancer\", \"therapeutic\", \"nursing\", \"pharmacology\", \"coordination\", \"variant\", \"medicine\", \"cra\", \"therapeutics\", \"dna\", \"pharma\", \"cell\", \"regulatory\", \"patient\", \"biology\", \"safety\", \"meetings\", \"drug\", \"scientific\", \"care\", \"studies\", \"monitoring\", \"budget\", \"site\", \"patients\", \"financial\", \"ensure\", \"activities\", \"process\", \"review\", \"support\", \"sciences\", \"medical\", \"reports\", \"functional\", \"internal\", \"health\", \"research\", \"processes\", \"reporting\", \"preferred\", \"provide\", \"requirements\", \"related\", \"analysis\", \"operations\", \"environment\", \"projects\", \"manage\", \"develop\", \"candidate\", \"industry\", \"quality\", \"company\", \"high\", \"signal\", \"computational\", \"cyber\", \"computing\", \"image\", \"mathematical\", \"sensor\", \"gap\", \"scala\", \"perl\", \"cleansing\", \"runs\", \"audio\", \"naive\", \"numerical\", \"mitigation\", \"uat\", \"sensing\", \"logistic\", \"unsupervised\", \"latency\", \"quant\", \"forests\", \"matlab\", \"hidden\", \"mixed\", \"scripting\", \"regression\", \"classified\", \"employ\", \"physics\", \"algorithms\", \"processing\", \"trading\", \"nlp\", \"simulation\", \"autonomous\", \"neural\", \"clearance\", \"model\", \"python\", \"machine\", \"models\", \"electrical\", \"citizen\", \"learning\", \"risk\", \"matter\", \"pricing\", \"spark\", \"systems\", \"software\", \"technologies\", \"analysis\", \"java\", \"statistics\", \"language\", \"computer\", \"engineering\", \"science\", \"using\", \"advanced\", \"testing\", \"requirements\", \"statistical\", \"techniques\", \"sql\", \"large\", \"complex\", \"tools\", \"design\", \"implementation\", \"related\", \"system\", \"preferred\", \"technical\", \"develop\", \"programming\", \"solutions\", \"informatica\", \"hub\", \"warehousing\", \"developer\", \"relocation\", \"marlborough\", \"etl\", \"recommending\", \"oracle\", \"cloud\", \"server\", \"subversion\", \"come\", \"interacting\", \"confidence\", \"spend\", \"monitors\", \"crm\", \"sponsorship\", \"agile\", \"primarily\", \"warehouse\", \"apis\", \"aggregate\", \"confidential\", \"saas\", \"demand\", \"sdlc\", \"upgrades\", \"keeping\", \"resolving\", \"summaries\", \"player\", \"thorough\", \"plus\", \"environments\", \"salesforce\", \"good\", \"sales\", \"users\", \"must\", \"understanding\", \"sql\", \"test\", \"user\", \"pharmaceutical\", \"design\", \"technical\", \"contract\", \"expertise\", \"programming\", \"end\", \"system\", \"teams\", \"software\", \"environment\", \"computer\", \"instrumentation\", \"microbiology\", \"capa\", \"calibration\", \"hplc\", \"cgmp\", \"deviation\", \"stability\", \"iso\", \"method\", \"finished\", \"instrument\", \"equipment\", \"regulated\", \"performed\", \"reagent\", \"water\", \"chromatography\", \"usp\", \"root\", \"investigations\", \"elisa\", \"revise\", \"qualification\", \"trending\", \"validation\", \"followed\", \"gmp\", \"trend\", \"release\", \"laboratory\", \"assay\", \"testing\", \"chemistry\", \"control\", \"assurance\", \"compliance\", \"quality\", \"maintenance\", \"analytical\", \"manufacturing\", \"environmental\", \"regulations\", \"perform\", \"troubleshooting\", \"training\", \"related\", \"protocols\", \"engineering\", \"support\", \"systems\", \"procedures\", \"requirements\", \"technical\", \"product\", \"reports\", \"review\", \"relevant\", \"methods\", \"metabolism\", \"bsc\", \"exceptionally\", \"frequently\", \"assays\", \"vitro\", \"advances\", \"developments\", \"scheduled\", \"takes\", \"specified\", \"throughput\", \"metabolic\", \"tight\", \"accountabilities\", \"communicates\", \"troubleshoot\", \"internally\", \"performed\", \"demonstrable\", \"interaction\", \"multitask\", \"pressure\", \"surface\", \"low\", \"experimental\", \"attending\", \"drug\", \"routine\", \"troubleshooting\", \"keep\", \"regulations\", \"motivated\", \"laboratory\", \"within\", \"able\", \"desirable\", \"scientist\", \"standard\", \"high\", \"responsibility\", \"effectively\", \"safety\", \"area\", \"position\", \"studies\", \"support\", \"candidate\", \"highly\", \"processing\", \"minimum\", \"self\", \"processes\", \"environment\", \"performance\", \"quality\", \"attending\", \"cycles\", \"dates\", \"adjustments\", \"actual\", \"protect\", \"discuss\", \"metric\", \"mix\", \"price\", \"autism\", \"room\", \"extend\", \"sheets\", \"consensus\", \"intervention\", \"compensation\", \"monday\", \"book\", \"weekend\", \"revenue\", \"installing\", \"hit\", \"weeks\", \"alerts\", \"penetration\", \"firewalls\", \"smes\", \"gives\", \"select\", \"workshops\", \"optimal\", \"confidentiality\", \"friday\", \"benchmarking\", \"weekly\", \"secondary\", \"nature\", \"necessary\", \"confidence\", \"demand\", \"daily\", \"net\", \"review\", \"maintain\", \"future\"], \"Total\": [361.0, 378.0, 362.0, 271.0, 278.0, 619.0, 446.0, 472.0, 236.0, 450.0, 306.0, 203.0, 497.0, 492.0, 338.0, 89.0, 230.0, 529.0, 365.0, 495.0, 473.0, 302.0, 205.0, 570.0, 461.0, 391.0, 122.0, 172.0, 431.0, 742.0, 180.27693838333195, 110.82139957145887, 51.445502589296815, 55.51576017166297, 132.89722976107086, 74.81102019048691, 57.344984092744305, 570.1554327304799, 121.96573839922374, 57.58246246823457, 23.48197043202418, 62.05420867413697, 22.00102010366765, 108.35026769602632, 126.6499354929087, 22.96101693823649, 28.520736409701836, 21.16639752943931, 20.76185232121857, 20.78900731341581, 19.226799580111543, 19.233381562893143, 19.924638052203868, 19.46908202059712, 16.743376284355524, 23.054574515523022, 85.03863847525335, 16.916412928595776, 20.358988414447875, 20.73955696697197, 32.03742093888956, 140.6022526038979, 89.46689710468074, 32.818598858093274, 62.20642330622172, 33.89398673333687, 453.8003854589046, 98.82036650083872, 82.60994266185496, 97.26644277207315, 37.92228215061758, 77.57879064947991, 51.19997688576788, 67.35915367761916, 284.27056645169785, 118.56056224136795, 239.9268589634986, 124.09849853212987, 91.65194475172139, 84.90656333206957, 428.3805147849729, 138.59408963529015, 130.26675364206065, 162.67867077581633, 535.9990700401308, 463.3392679756253, 224.01179435234084, 190.62258875150357, 286.9277981817453, 186.41792306397906, 153.45277325923846, 268.9348855210461, 627.2515179862088, 211.78481196384922, 337.9291813659322, 203.57006461575622, 450.6201828048157, 388.97461959887465, 334.9869139046915, 341.47058329544103, 504.7454576382519, 217.13864553865866, 357.9694155710227, 355.143205824521, 320.9341477808771, 515.8477979536655, 497.5096944327483, 742.8902889166817, 389.631603821335, 381.5724070326103, 315.9925239645019, 311.7675236366306, 619.5398595108892, 362.13439438913366, 472.77811409491505, 77.97705165322265, 153.48968041571592, 63.6850989022367, 92.36159694333955, 53.20564794874223, 40.31569366905993, 33.277497264251295, 28.35672418908784, 28.280887690551683, 45.235636471584506, 28.12529375351247, 29.064562778638265, 25.909785276384827, 24.278873709626673, 47.55853318832654, 23.32585348544081, 25.8941162448172, 22.781302312722367, 58.68978602329717, 22.837036991677117, 23.06208183074614, 20.876760016993373, 29.70785636874786, 22.009001812039962, 21.520351812633272, 18.86777763265323, 18.787056968994467, 18.882088288612167, 19.499167676614633, 99.97279311593879, 167.89306815994016, 84.2512371082926, 99.16766462633957, 67.14554930761382, 87.04854250747903, 91.55611510727357, 154.4884667767235, 142.27845739462205, 101.0183801366788, 89.95816140664807, 75.91665613929321, 120.08361339882336, 59.679169875405975, 263.53830782370784, 284.6566353395339, 229.41109072098513, 326.9858281998429, 164.97254822622386, 619.5398595108892, 107.76992300409177, 150.3734082290824, 246.3845449019319, 187.42558310991248, 248.32235840409615, 287.8201456161693, 627.2515179862088, 260.238282482536, 285.6383011541187, 379.90247337968765, 379.3077959410964, 484.39583670970666, 461.18278203798263, 742.8902889166817, 263.9354617571555, 431.65467587374224, 389.631603821335, 320.9341477808771, 504.7454576382519, 302.9316643816234, 355.143205824521, 378.6423830714237, 463.3392679756253, 362.13439438913366, 27.89432897833764, 53.732352225787395, 21.361750763745547, 69.97658188397105, 27.378380872966794, 29.470050623263273, 19.052984240912203, 13.645686536783852, 37.107071460057405, 22.677076083476827, 10.234367484435568, 7.846547560078927, 21.058383266125684, 7.973589818848623, 9.825593712018895, 7.918651887054324, 7.457437423656677, 19.68788602452586, 8.2154824299397, 15.18954735616687, 9.913186807785634, 8.994622411648262, 7.971892641109945, 58.3917261124178, 7.7876824965569655, 6.905863580418038, 57.86730174873317, 37.33415422535862, 6.610628769890022, 13.52107012888866, 55.28913535716317, 164.59865289480453, 141.3720062117531, 46.315040680282294, 37.97310739474895, 18.35332946254817, 20.624994962002233, 31.902139413951947, 14.887489196663191, 101.81261853983183, 270.6570856816691, 365.63924268147736, 284.16148991766596, 36.97109411546901, 23.434842533988476, 497.5096944327483, 137.30808562565426, 48.265973461814944, 76.43945196471613, 64.57714041524646, 473.5131015458856, 418.8870382681356, 246.57570716990708, 742.8902889166817, 113.4531974660365, 187.43096627802896, 107.67046346119137, 308.87211789615867, 290.558363772367, 515.8477979536655, 298.2848606490033, 184.99824872767832, 278.51216164717874, 484.39583670970666, 294.22594742442607, 180.86878490348477, 278.38762994798043, 203.74289161758415, 246.51469896208212, 388.97461959887465, 529.6159592154855, 216.58544359470469, 461.18278203798263, 292.91802207145975, 379.90247337968765, 495.6436053606882, 504.7454576382519, 280.711094000211, 357.9694155710227, 361.6871277335688, 104.58966244291648, 108.48371003680606, 129.8013934405574, 57.28300042828923, 54.27469562770451, 230.7576698992255, 54.16450191644465, 205.77140693695353, 165.96965601219193, 32.85032337739891, 53.97631602363896, 59.20446072025476, 55.85594659910549, 56.87418393944437, 112.81779526671055, 55.90842779836476, 130.58787251913722, 58.100000472840165, 26.513806019407635, 59.40730399307603, 74.18961258598084, 14.68551614910062, 111.04907868834799, 57.706393121706824, 12.1419109310453, 64.88452650969379, 60.34737594101408, 11.921632890603949, 61.56661934017592, 59.074275494851605, 58.357356037704506, 131.22597545532656, 128.8471575596607, 446.2987563017985, 83.2955633711613, 76.18310585714028, 250.75089193463805, 338.0879253740603, 101.40283372086097, 492.87421487464746, 391.70499736010123, 278.38762994798043, 242.21009904460942, 126.82517855198519, 171.41615851640583, 529.6159592154855, 495.6436053606882, 259.29382583051205, 264.90649556507583, 280.711094000211, 152.501708691462, 292.91802207145975, 310.09973417012236, 418.8870382681356, 431.65467587374224, 308.87211789615867, 23.72327175976066, 19.26945201899668, 11.397147419943641, 12.185248567716304, 8.950400637856463, 15.499241919037066, 6.709250766635512, 34.8391792239109, 9.819288177319997, 28.23927585716849, 6.055270934810879, 12.416443578284118, 74.65766780616315, 12.431766730349594, 12.957537644849358, 11.016126483782104, 7.589416965660628, 12.505873019268403, 5.634465443873011, 14.620271988380386, 14.677499139820341, 7.433265630877908, 6.2363891995135114, 44.23467387879626, 8.064901667763468, 95.655292360516, 5.229877594757432, 23.721693222705685, 15.36064065510438, 32.494788207240994, 122.47127168647168, 35.72694796491486, 278.51216164717874, 31.528830592227198, 140.36010961490072, 45.30883400719715, 109.91015297425102, 378.6423830714237, 76.96147263305538, 306.286907529012, 114.83114778768665, 53.66754944362037, 46.46165975624882, 189.97143541332613, 33.363750229183516, 217.91473539364668, 461.18278203798263, 56.80227042916675, 290.558363772367, 619.5398595108892, 473.5131015458856, 142.11638889276736, 484.39583670970666, 495.6436053606882, 341.47058329544103, 246.3845449019319, 164.97254822622386, 215.36707540630934, 159.55756055541738, 7.131638917123551, 4.765099749255607, 4.991599014262175, 7.48048605611601, 42.04658282911877, 22.36962946672029, 7.650197602270633, 15.003273603080983, 7.915504762861842, 15.080829466162623, 8.59611486274539, 20.030650492037516, 10.352833265617273, 16.579167526581372, 11.693398994721132, 12.328999613427564, 22.959270567132805, 12.566925349155659, 12.957537644849358, 16.67300276751573, 25.302701854955366, 17.298539996292707, 25.928794732685905, 11.858767767217339, 18.101320802443357, 36.32338719850213, 2.9681318011753706, 91.55611510727357, 22.37123858565774, 33.363750229183516, 31.110738789797015, 46.46165975624882, 98.13407401611884, 122.47127168647168, 271.351256698024, 203.45882900643292, 50.57871429441765, 236.0583455921172, 69.72525504017955, 362.13439438913366, 57.154462976218234, 161.4364420207751, 67.14554930761382, 103.03192164433162, 450.6201828048157, 101.0183801366788, 619.5398595108892, 302.9316643816234, 222.3951384129194, 141.3720062117531, 191.74914582597958, 144.60343911716663, 260.238282482536, 431.65467587374224, 228.03313996960068, 378.6423830714237, 2.9681318011753706, 3.9838913715294506, 6.515392925324812, 7.491809849496474, 8.152093023149785, 4.577014992776798, 5.134270923741734, 4.973232142685841, 6.174105939742426, 7.171845533757601, 9.218008922079065, 7.428520621554355, 10.503692662824498, 6.723825132987489, 7.813429781094738, 5.849274748815801, 89.33670235949869, 8.727577049449518, 6.777330639894245, 9.159150715615125, 32.56830949937993, 2.63139540723894, 2.598447758350806, 6.777800693635974, 2.6395853339730952, 2.632234397845967, 2.658884309355161, 2.6870485178524937, 2.6988031573288325, 2.719350979372487, 7.657693874999266, 7.779287955023212, 10.514146100840273, 10.349738531263153, 10.675772561083267, 30.241882354312995, 11.518034060510178, 12.275920564253237, 71.48601829224411, 56.87418393944437, 64.88452650969379, 50.50891932053625, 20.471775047151308, 164.97254822622386, 194.2125447056754, 75.41856792195964], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8719, 0.8706, 0.8644, 0.864, 0.8639, 0.8636, 0.8591, 0.8553, 0.8536, 0.8498, 0.8471, 0.8467, 0.8448, 0.8436, 0.8434, 0.8433, 0.8427, 0.8424, 0.8419, 0.8402, 0.8399, 0.839, 0.839, 0.8388, 0.8375, 0.8372, 0.8348, 0.8316, 0.8311, 0.8303, 0.8265, 0.8055, 0.8063, 0.8252, 0.8049, 0.8226, 0.7428, 0.7891, 0.7881, 0.7814, 0.8179, 0.7852, 0.805, 0.7911, 0.7129, 0.7557, 0.6968, 0.7389, 0.7557, 0.7601, 0.6246, 0.6977, 0.7037, 0.6585, 0.4669, 0.4793, 0.5957, 0.62, 0.5194, 0.6092, 0.6454, 0.5102, 0.229, 0.5338, 0.3515, 0.5184, 0.2043, 0.2463, 0.3032, 0.2897, 0.0911, 0.4642, 0.1922, 0.181, 0.2392, -0.0473, -0.0456, -0.3565, 0.0693, 0.0779, 0.1754, 0.1661, -0.441, 0.0302, 1.2746, 1.2678, 1.2669, 1.265, 1.2641, 1.2631, 1.2597, 1.254, 1.2518, 1.2514, 1.2513, 1.2503, 1.2494, 1.2468, 1.2461, 1.2454, 1.2448, 1.2448, 1.2445, 1.2443, 1.2433, 1.2426, 1.2404, 1.2403, 1.24, 1.238, 1.2373, 1.237, 1.2368, 1.2362, 1.2114, 1.1843, 1.2002, 1.1897, 1.1827, 1.1624, 1.1341, 1.0775, 1.0438, 1.0554, 1.0678, 1.0851, 0.9857, 1.0995, 0.8289, 0.7859, 0.827, 0.7346, 0.8748, 0.5521, 0.9519, 0.8566, 0.7064, 0.7704, 0.6743, 0.5792, 0.2424, 0.6055, 0.5397, 0.405, 0.4017, 0.2421, 0.219, -0.0571, 0.5057, 0.1419, 0.2035, 0.333, 0.0056, 0.3529, 0.2241, 0.1668, -0.0074, 0.1708, 1.818, 1.8153, 1.8048, 1.7888, 1.7758, 1.7677, 1.7636, 1.7633, 1.7562, 1.7546, 1.7545, 1.7489, 1.7474, 1.7463, 1.7463, 1.7451, 1.7447, 1.7446, 1.7438, 1.7421, 1.7407, 1.7405, 1.7392, 1.7385, 1.7341, 1.733, 1.7319, 1.7306, 1.7293, 1.7288, 1.7205, 1.7044, 1.6599, 1.6928, 1.6972, 1.7149, 1.7089, 1.6727, 1.7143, 1.5902, 1.5203, 1.4794, 1.4774, 1.6302, 1.6726, 1.334, 1.4464, 1.5766, 1.5011, 1.5201, 1.1075, 1.1278, 1.2273, 0.9737, 1.3853, 1.2616, 1.3267, 1.0102, 0.9862, 0.7662, 0.9545, 1.1222, 0.9613, 0.6774, 0.8792, 1.0722, 0.8534, 1.0059, 0.9017, 0.6155, 0.3991, 0.9362, 0.4357, 0.7235, 0.5003, 0.2818, 0.2565, 0.7157, 0.4729, 2.1413, 2.1348, 2.1342, 2.1332, 2.1278, 2.1271, 2.127, 2.1262, 2.1163, 2.1145, 2.1117, 2.1052, 2.0972, 2.0941, 2.0884, 2.0862, 2.086, 2.0852, 2.0836, 2.0824, 2.079, 2.079, 2.0785, 2.0709, 2.0697, 2.065, 2.0645, 2.0549, 2.0517, 2.0458, 2.0366, 2.0365, 1.9974, 1.9863, 1.7965, 1.9948, 1.9975, 1.8029, 1.6967, 1.9437, 1.5453, 1.541, 1.583, 1.5988, 1.8081, 1.6637, 1.2021, 1.2233, 1.4653, 1.4457, 1.4028, 1.6118, 1.1938, 1.0182, 0.7366, 0.6467, 0.9295, 3.4742, 3.4729, 3.4334, 3.4024, 3.397, 3.3825, 3.3711, 3.3605, 3.3155, 3.3084, 3.3025, 3.2606, 3.2266, 3.2261, 3.1817, 3.1714, 3.162, 3.15, 3.0982, 3.0956, 3.0564, 3.0489, 3.0434, 3.0268, 2.9899, 2.9514, 2.903, 2.8635, 2.8544, 2.8381, 2.7167, 2.7652, 2.5249, 2.7485, 2.4314, 2.6543, 2.4033, 1.9916, 2.4778, 1.9023, 2.2689, 2.5595, 2.6147, 1.8582, 2.6261, 1.4636, 0.9406, 2.245, 1.0934, 0.5178, 0.6937, 1.5707, 0.6282, 0.5531, 0.85, 1.0976, 1.4315, 1.1346, 1.381, 4.2438, 4.0017, 3.9564, 3.9257, 3.662, 3.6487, 3.5268, 3.5019, 3.4955, 3.4954, 3.4104, 3.363, 3.2225, 3.128, 3.1031, 3.051, 3.0368, 3.0322, 3.0021, 2.7486, 2.7166, 2.7117, 2.6826, 2.6775, 2.6676, 2.6109, 2.5662, 2.515, 2.4565, 2.4322, 2.4007, 2.3684, 2.1743, 2.0663, 1.7184, 1.7681, 2.2816, 1.5953, 2.1257, 1.2322, 2.1615, 1.5115, 1.9949, 1.683, 0.6372, 1.631, 0.2074, 0.7557, 0.8953, 1.2659, 1.0009, 1.2343, 0.6541, 0.1465, 0.7812, 0.2723, 4.3108, 4.0155, 4.0033, 3.8307, 3.6908, 3.6778, 3.5543, 3.5068, 3.2253, 3.1895, 3.1727, 2.9883, 2.9608, 2.9461, 2.9431, 2.9371, 2.7812, 2.7364, 2.7362, 2.7267, 2.7261, 2.6611, 2.6609, 2.656, 2.6534, 2.6478, 2.6367, 2.6251, 2.6239, 2.6207, 2.4396, 2.4228, 2.3516, 2.2685, 2.1641, 1.7255, 2.0497, 1.9622, 1.0533, 1.1664, 0.7903, 0.9529, 1.6639, -0.0202, -0.2687, 0.5328], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6871, -6.1749, -6.9485, -6.8728, -6.0, -6.5748, -6.8452, -4.5522, -6.0961, -6.8504, -7.75, -6.7787, -7.8176, -6.2245, -6.0686, -7.7763, -7.5601, -7.8586, -7.8784, -7.8788, -7.9572, -7.9577, -7.9225, -7.9457, -8.0979, -7.7783, -6.4755, -8.0935, -7.9088, -7.891, -7.46, -6.002, -6.4533, -7.4372, -6.818, -7.4076, -4.8929, -6.371, -6.5512, -6.3946, -7.3, -6.6169, -7.0127, -6.7523, -5.3906, -6.2223, -5.5763, -6.1934, -6.4797, -6.5518, -5.0688, -6.1242, -6.1802, -6.0031, -5.0024, -5.1356, -5.746, -5.8831, -5.5748, -5.9163, -6.0746, -5.6488, -5.0831, -5.864, -5.5791, -5.919, -5.4385, -5.5436, -5.6361, -5.6305, -5.4383, -5.9087, -5.6807, -5.6999, -5.743, -5.5549, -5.5894, -5.4994, -5.7189, -5.7312, -5.8223, -5.8451, -5.7654, -5.8312, -4.3202, -6.1292, -5.4529, -6.3344, -5.9636, -6.5162, -6.797, -6.9946, -7.1568, -7.1598, -6.6902, -7.1664, -7.1345, -7.252, -7.3177, -6.6461, -7.359, -7.2546, -7.383, -6.4369, -7.3817, -7.3726, -7.4743, -7.1217, -7.4219, -7.4465, -7.5787, -7.5833, -7.5784, -7.5469, -5.9371, -5.4458, -6.1194, -5.9669, -6.3639, -6.1245, -6.1024, -5.6358, -5.7518, -6.0827, -6.1862, -6.3386, -5.9796, -6.5649, -5.3503, -5.3162, -5.4909, -5.2289, -5.7729, -4.7723, -6.1215, -5.8837, -5.5402, -5.7497, -5.5644, -5.5119, -5.0697, -5.5863, -5.5589, -5.4085, -5.4134, -5.3284, -5.4006, -5.2, -5.672, -5.5439, -5.5847, -5.6491, -5.5238, -5.687, -5.6568, -5.65, -5.6223, -5.6906, -6.607, -5.9541, -6.887, -5.7165, -6.6679, -6.6024, -7.0426, -7.3767, -6.3834, -6.8775, -7.6731, -7.9444, -6.9588, -7.931, -7.7221, -7.9391, -7.9995, -7.0288, -7.9036, -7.2907, -7.7189, -7.8163, -7.9383, -5.9477, -7.9668, -8.088, -5.9634, -6.4029, -8.1354, -7.4204, -6.0203, -4.9455, -5.1421, -6.2252, -6.4193, -7.1287, -7.018, -6.6181, -7.3386, -5.5401, -4.6323, -4.3724, -4.6265, -6.5131, -6.9266, -4.2098, -5.3848, -6.3001, -5.9159, -6.0654, -4.4858, -4.588, -5.0184, -4.1691, -5.6367, -5.2584, -5.7477, -5.0103, -5.0955, -4.7414, -5.1009, -5.4108, -5.1626, -4.8931, -5.1899, -5.4835, -5.271, -5.4307, -5.3443, -5.1744, -5.0822, -5.4392, -5.1839, -5.35, -5.3132, -5.2657, -5.2728, -5.4004, -5.4, -3.7214, -4.9686, -4.9326, -4.7542, -5.5776, -5.6322, -4.1851, -5.6352, -4.3103, -4.5271, -6.1497, -5.6596, -5.5753, -5.6366, -5.6242, -4.9415, -5.6437, -4.7961, -5.6077, -6.3933, -5.59, -5.3678, -6.9881, -4.9725, -5.6284, -7.1917, -5.5163, -5.5984, -7.2234, -5.5875, -5.638, -5.6504, -4.8791, -4.9085, -3.8559, -5.3363, -5.4228, -4.4261, -4.2334, -5.1906, -4.0079, -4.2419, -4.5414, -4.6648, -5.1025, -4.9456, -4.2792, -4.3242, -4.7301, -4.7283, -4.7133, -5.1144, -4.8798, -4.9984, -4.9793, -5.0391, -5.091, -5.1128, -5.322, -5.8866, -5.8508, -6.1648, -5.6301, -6.4789, -4.8422, -6.1536, -5.1043, -6.65, -5.9738, -4.2139, -6.0071, -6.0101, -6.1826, -6.5647, -6.0772, -6.9264, -5.9754, -6.0107, -6.6985, -6.8796, -4.9371, -6.676, -4.2412, -7.1961, -5.7235, -6.1672, -5.4343, -4.2289, -5.4123, -3.5991, -5.5541, -4.3779, -5.2856, -4.6505, -3.8252, -4.9323, -4.1266, -4.7411, -5.2111, -5.3001, -4.6483, -5.6198, -4.9057, -4.679, -5.4689, -4.9882, -4.8066, -4.8995, -5.2261, -4.9424, -4.9944, -5.0701, -5.149, -5.2161, -5.2464, -5.3, -5.545, -6.1904, -6.1893, -5.8154, -4.3527, -4.997, -6.1919, -5.5433, -6.1891, -5.5446, -6.1917, -5.3932, -6.1936, -5.8172, -6.1913, -6.1904, -5.5829, -6.1902, -6.1897, -6.1911, -5.8059, -6.1911, -5.8155, -6.6029, -6.1898, -5.5501, -8.0993, -4.7215, -6.1891, -5.8137, -5.9151, -5.5464, -4.9928, -4.8793, -4.4316, -4.6699, -5.5483, -4.694, -5.3831, -4.6292, -5.5462, -5.1578, -5.5516, -5.4354, -5.0056, -5.5071, -5.1171, -5.2842, -5.4537, -5.5361, -5.4963, -5.5451, -5.5377, -5.5393, -5.5427, -5.5445, -6.3547, -6.3557, -5.8759, -5.9089, -5.9644, -6.5546, -6.5631, -6.6426, -6.7077, -6.5937, -6.3596, -6.7598, -6.4409, -6.9017, -6.7545, -7.05, -4.4798, -6.8505, -7.1036, -6.8119, -5.544, -8.1248, -8.1376, -7.1837, -8.1294, -8.1378, -8.1388, -8.1399, -8.1367, -8.1323, -7.2781, -7.2792, -7.0491, -7.148, -7.2213, -6.6187, -7.2598, -7.2835, -6.4306, -6.5461, -6.7905, -6.8784, -7.0705, -6.6678, -6.7532, -6.8976]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 6, 1, 2, 3, 6, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 2, 4, 1, 2, 1, 2, 3, 4, 5, 2, 4, 6, 1, 1, 3, 4, 3, 4, 4, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 6, 2, 5, 2, 5, 6, 1, 2, 3, 4, 5, 4, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 2, 3, 5, 2, 2, 1, 1, 2, 2, 4, 6, 1, 2, 1, 2, 3, 4, 3, 5, 1, 1, 2, 1, 2, 1, 2, 3, 4, 6, 5, 1, 2, 3, 4, 5, 1, 2, 5, 6, 2, 5, 2, 5, 2, 5, 1, 2, 3, 4, 3, 3, 2, 3, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 4, 3, 4, 1, 4, 2, 3, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 3, 4, 1, 3, 4, 3, 4, 1, 2, 3, 5, 1, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 2, 1, 3, 4, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 4, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 4, 2, 3, 4, 1, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 3, 4, 1, 3, 4, 6, 5, 1, 2, 4, 1, 2, 3, 2, 1, 2, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 2, 5, 1, 2, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 5, 1, 2, 3, 4, 1, 2, 4, 5, 6, 3, 4, 1, 3, 4, 6, 2, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 5, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 2, 1, 2, 2, 4, 2, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 4, 5, 4, 2, 1, 3, 1, 2, 3, 4, 5, 1, 2, 4, 6, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 4, 2, 5, 5, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 1, 2, 3, 4, 6, 2, 4, 6, 1, 2, 1, 2, 5, 2, 4, 5, 1, 3, 4, 1, 2, 4, 5, 6, 2, 4, 1, 1, 2, 3, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 3, 4, 1, 2, 4, 3, 1, 2, 3, 4, 1, 3, 4, 6, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 4, 4, 1, 3, 1, 3, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 6, 2, 6, 2, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 1, 2, 3, 4, 5, 6, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 3, 1, 2, 3, 4, 2, 4, 1, 2, 4, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 3, 1, 2, 1, 2, 3, 4, 1, 3, 4, 1, 3, 1, 2, 3, 4, 5, 2, 3, 1, 3, 3, 2, 2, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 4, 2, 4, 1, 2, 3, 1, 2, 4, 1, 2, 4, 1, 2, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 4, 5, 6, 3, 4, 1, 2, 2, 2, 4, 5, 2, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 6, 3, 1, 2, 5, 1, 3, 4, 4, 1, 3, 2, 5, 1, 2, 3, 5, 6, 2, 3, 5, 6, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 4, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 4, 5, 2, 3, 5, 6, 3, 4, 1, 2, 4, 6, 1, 2, 4, 1, 3, 4, 1, 3, 4, 2, 4, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 3, 4, 3, 4, 1, 2, 4, 1, 2, 5, 1, 4, 1, 2, 3, 4, 5, 6, 1, 1, 3, 3, 4, 1, 4, 1, 2, 3, 4, 5, 1, 4, 3, 1, 3, 1, 2, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 3, 4, 2, 6, 3, 4, 1, 2, 4, 1, 3, 4, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 6, 1, 2, 3, 3, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 5, 6, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 4, 2, 3, 4, 5, 2, 3, 6, 1, 2, 6, 1, 2, 3, 4, 2, 1, 3, 4, 1, 2, 3, 4, 5, 1, 4, 5, 3, 5, 2, 2, 1, 2, 4, 5, 6, 2, 4, 5, 6, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 6, 2, 2, 6, 1, 4, 4, 1, 5, 1, 2, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 3, 4], \"Freq\": [0.40794494102477963, 0.30472995594622093, 0.21625996873602776, 0.044234993605096584, 0.02457499644727588, 0.3420733357175069, 0.42759166964688367, 0.08551833392937673, 0.08551833392937673, 0.9852579753014141, 0.6585654048143206, 0.2256622715797322, 0.06447493473706635, 0.046053524812190244, 0.15692353794605335, 0.6364121261145498, 0.11769265345954003, 0.008717974330336298, 0.07410278180785854, 0.004358987165168149, 0.7360073030277733, 0.1226678838379622, 0.5339163807352693, 0.40043728555145197, 0.3513546773930898, 0.14054187095723591, 0.4810856351997691, 0.021621826301113218, 0.0054054565752783045, 0.6535778890882459, 0.13071557781764917, 0.13071557781764917, 0.9719022554636768, 0.009005027433018467, 0.0540301645981108, 0.927517825600902, 0.03771619960061629, 0.9429049900154072, 0.75769476904526, 0.12758306116527673, 0.8627045088318712, 0.006075383865013178, 0.28941016352969606, 0.26248828785251505, 0.4159429792124469, 0.021537500541744824, 0.010768750270872412, 0.41790881965098564, 0.15998072002264294, 0.1958947592113995, 0.02938421388170993, 0.19915967186492284, 0.8682231497039572, 0.03525779288137897, 0.0617011375424132, 0.03525779288137897, 0.9533202549954226, 0.40764065475731776, 0.3688177352566208, 0.10676302862691656, 0.029117189625522698, 0.06794010912621963, 0.019411459750348466, 0.5038213736498468, 0.47583129733596635, 0.713494366995834, 0.118915727832639, 0.16648201896569462, 0.13242450686431087, 0.06621225343215544, 0.33106126716077716, 0.044141502288103616, 0.41934427173698435, 0.6738245246413944, 0.9022534997054223, 0.04748702630028538, 0.8678663763102162, 0.04848486032807845, 0.04848486032807845, 0.8727274859054122, 0.49368256578603353, 0.31646318319617533, 0.12342064144650838, 0.056963372975311566, 0.00949389549588526, 0.7493602879067183, 0.09367003598833978, 0.09367003598833978, 0.9176378242130128, 0.06050359280525359, 0.020167864268417865, 0.9616107769731932, 0.9633724826089353, 0.8853043061941605, 0.9725183258859842, 0.017366398676535433, 0.4197183910604254, 0.2098591955302127, 0.2098591955302127, 0.15806807899945158, 0.8166850748304998, 0.7035443128255754, 0.10387902605478294, 0.11332257387794503, 0.08027015649687773, 0.08206644242362097, 0.9027308666598307, 0.9726967591369368, 0.9835645500011538, 0.009023527981661962, 0.017038739919805562, 0.971208175428917, 0.3697203467607997, 0.39612894295799966, 0.17825802433109986, 0.04951611786974996, 0.009903223573949991, 0.87741253416633, 0.1335409474345213, 0.787188742771915, 0.049199296423244686, 0.0070284709176063834, 0.014056941835212767, 0.9332487259787691, 0.9302530928804559, 0.05001360714411053, 0.010002721428822105, 0.06451928457041128, 0.903269983985758, 0.5074720406517227, 0.47575503811099007, 0.2398872909854238, 0.7196618729562714, 0.04267150498449736, 0.04267150498449736, 0.8534300996899472, 0.08534300996899472, 0.907629245092191, 0.879389958752918, 0.06717049374747053, 0.873216418717117, 0.770343161302854, 0.07936868934635466, 0.1027124215070472, 0.04435309110531584, 0.0023343732160692543, 0.8407483158852113, 0.07387328298572986, 0.05628440608436561, 0.028142203042182803, 0.0021151571322509228, 0.9941238521579336, 0.0021151571322509228, 0.024100791048853924, 0.9700568397163704, 0.03378123836732743, 0.9458746742851681, 0.405547907922268, 0.32443832633781444, 0.16221916316890722, 0.08110958158445361, 0.8297612135021204, 0.12266035330031345, 0.03607657450009219, 0.007215314900018439, 0.6668979328042954, 0.2762554543655334, 0.0064747372116921885, 0.03237368605846094, 0.015107720160615106, 0.0021582457372307296, 0.8507141856901027, 0.06716164623869232, 0.01119360770644872, 0.04477443082579488, 0.01119360770644872, 0.3894291107353656, 0.1582055762362423, 0.3853725574985389, 0.056791745315574155, 0.00811310647365345, 0.04549170267437772, 0.49131038888327944, 0.12737676748825763, 0.009098340534875545, 0.3275402592555196, 0.018610761646873836, 0.9677596056374395, 0.1942551513185522, 0.03561344440840124, 0.43059891875612405, 0.2978578986884467, 0.042088616119019644, 0.9431726761023471, 0.04287148527737941, 0.017582669864146614, 0.017582669864146614, 0.9494641726639172, 0.051987307431826314, 0.9357715337728736, 0.09510995856525921, 0.475549792826296, 0.2853298756957776, 0.09510995856525921, 0.5119390731172042, 0.2559695365586021, 0.12798476827930105, 0.9047313491890782, 0.05140519029483399, 0.010281038058966798, 0.03084311417690039, 0.9674848162174617, 0.016398047732499352, 0.008199023866249676, 0.003856628659772455, 0.2391109769058922, 0.20440131896794012, 0.509074983089964, 0.042422915257497, 0.09261890743507878, 0.24223406559943678, 0.2564831282817566, 0.06412078207043916, 0.33485297303451556, 0.007124531341159906, 0.9761727551136099, 0.9540074273956132, 0.03063071572296128, 0.01531535786148064, 0.9418945084810594, 0.9657042296354567, 0.9759063103180283, 0.6935542713569697, 0.09758552561806609, 0.07318914421354956, 0.12546710436608496, 0.010455592030507081, 0.7659113274887177, 0.04196774397198453, 0.03672177597548646, 0.13639516790894973, 0.005245967996498066, 0.005245967996498066, 0.90559332577048, 0.04453737667723672, 0.02969158445149115, 0.9362528484296022, 0.7530325805164396, 0.2969772507863022, 0.15838786708602787, 0.4157681511008231, 0.019798483385753483, 0.09899241692876741, 0.019798483385753483, 0.30696536999728136, 0.30696536999728136, 0.15348268499864068, 0.046235985085778475, 0.015411995028592826, 0.9247197017155695, 0.8996579805783235, 0.059977198705221564, 0.17937525927413986, 0.19448054426564637, 0.23413191736835098, 0.38896108853129274, 0.0018881606239383143, 0.23725395489786966, 0.4745079097957393, 0.21748279198971385, 0.039542325816311605, 0.039542325816311605, 0.45171283178422633, 0.2793487249191926, 0.2020820563245223, 0.05151111239644686, 0.013868376414428, 0.0077040775410315634, 0.9861219252520401, 0.533216963953598, 0.266608481976799, 0.06665212049419975, 0.1333042409883995, 0.8942876348932207, 0.9873697745049875, 0.0055470212050842, 0.0055470212050842, 0.3895392412487746, 0.1947696206243873, 0.1947696206243873, 0.986030372451572, 0.9542574722073938, 0.9532843891454444, 0.03276679003346734, 0.8628588042146399, 0.021844526688978225, 0.021844526688978225, 0.05461131672244556, 0.3221081891368008, 0.45838473069467806, 0.10530460029472333, 0.05574949427367706, 0.037166329515784705, 0.018583164757892352, 0.8114447440019839, 0.18933710693379624, 0.2690607465569328, 0.672651866392332, 0.9277174316539206, 0.05588659226830847, 0.011177318453661694, 0.07395864310055118, 0.8875037172066143, 0.08524494650942768, 0.15737528586355878, 0.16393258944120706, 0.5901573219883455, 0.28221524562356604, 0.09980783076930994, 0.4198812190984763, 0.1101327787799282, 0.08948288275869166, 0.20726725702222165, 0.6112627579977384, 0.07026008712617683, 0.049182060988323784, 0.06323407841355914, 0.0035130043563088415, 0.33823333363520564, 0.31970000028533135, 0.09961666675557426, 0.22471666686722566, 0.011583333343671426, 0.00463333333746857, 0.5962634838323876, 0.3912979112650044, 0.036016324022350804, 0.012005441340783601, 0.08403808938548521, 0.8643917765364192, 0.12055024305563736, 0.09376130015438462, 0.013394471450626373, 0.750090401235077, 0.013394471450626373, 0.013000651294971622, 0.983715947986186, 0.40067320998452166, 0.20033660499226083, 0.20033660499226083, 0.20033660499226083, 0.8809751090977436, 0.027530472159304487, 0.05506094431860897, 0.11702242307752196, 0.24914451364891774, 0.1283471736979273, 0.4982890272978355, 0.007549833746936901, 0.0037749168734684505, 0.7616369077814161, 0.09520461347267702, 0.09520461347267702, 0.14039704627970404, 0.6374784804051427, 0.20869831203739792, 0.015178059057265303, 0.8257268838716566, 0.752195194414098, 0.38241812810396425, 0.5736271921559464, 0.8780850815654454, 0.40104345860617097, 0.40104345860617097, 0.2673623057374473, 0.3864831935528919, 0.3864831935528919, 0.09662079838822298, 0.07469631289230107, 0.6029059540592872, 0.23475984051866047, 0.08536721473405835, 0.005335450920878647, 0.9633051854222102, 0.6762260462539268, 0.09281533968191152, 0.13259334240273077, 0.039778002720819224, 0.0530373369610923, 0.879398773205901, 0.9599899733181654, 0.9643407538478413, 0.965470293082655, 0.9648864216094434, 0.7410692382543083, 0.46371057481980815, 0.5058660816216088, 0.035892195359951036, 0.0598203255999184, 0.1316047163198205, 0.7098678637856983, 0.0598203255999184, 0.9757920666517363, 0.013367014611667621, 0.9078810320326146, 0.024210160854203057, 0.060525402135507646, 0.44819656290505666, 0.49683805035211703, 0.048641487447060414, 0.0034743919605043153, 0.0034743919605043153, 0.7499605120601743, 0.11160126667562117, 0.06696076000537271, 0.06696076000537271, 0.8988553402241026, 0.42525648595123056, 0.32860728459867816, 0.17396856243459433, 0.05522811505860137, 0.013807028764650342, 0.44965011696582474, 0.42267110994787527, 0.06295101637521547, 0.031475508187607734, 0.026979007017949485, 0.008993002339316495, 0.769690286661514, 0.8938147378747869, 0.9943621345633628, 0.9547083633099815, 0.03652516942619468, 0.913129235654867, 0.2585584657517083, 0.26779269667141214, 0.4016890450071182, 0.06002250097807514, 0.013851346379555802, 0.7318761535812051, 0.20910747245177286, 0.04065978631006695, 0.01161708180287627, 0.4955747346803052, 0.34915492670657866, 0.06194684183503815, 0.04505224860730047, 0.05068377968321303, 0.9981002151282671, 0.9245940060877518, 0.04267356951174239, 0.0071122615852903985, 0.021336784755871196, 0.7600530100865959, 0.16107671954455002, 0.80538359772275, 0.9695121411968365, 0.8771888226059078, 0.042172539548360956, 0.03373803163868876, 0.042172539548360956, 0.035806393441947845, 0.017903196720973923, 0.9488694262116179, 0.31617176876441966, 0.23712882657331474, 0.31617176876441966, 0.07904294219110491, 0.03952147109555246, 0.07904294219110491, 0.917969164417038, 0.05859377645215136, 0.35840510122399, 0.5476752108591307, 0.06040535413887472, 0.03221618887406651, 0.004027023609258314, 0.6365916704150312, 0.23872187640563672, 0.0795739588018789, 0.5128840974015381, 0.3419227316010253, 0.2043944933276093, 0.13626299555173954, 0.613183479982828, 0.947325657486344, 0.10184037599688132, 0.8147230079750506, 0.11458469474949524, 0.6258087174780125, 0.25561201136425865, 0.41786214361014923, 0.41786214361014923, 0.06428648363233065, 0.032143241816165326, 0.032143241816165326, 0.08121283990555576, 0.9095838069422245, 0.9458269946197249, 0.008165180178417802, 0.47358045034823254, 0.024495540535253407, 0.44908490981297916, 0.03266072071367121, 0.3436411324943933, 0.02786279452657243, 0.5944062832335452, 0.03715039270209657, 0.44664134919024673, 0.07362220041597474, 0.4270087624126535, 0.04417332024958484, 0.9078816100723096, 0.8622183287116648, 0.02417434566481303, 0.06446492177283475, 0.04834869132962606, 0.39396217238234066, 0.5949632807406777, 0.008040044334333482, 0.8837783008251844, 0.032732529660192015, 0.07637590254044803, 0.8520497803622445, 0.8294194358217933, 0.11670223217593073, 0.012503810590278292, 0.04167936863426097, 0.2762229372414133, 0.5524458744828266, 0.1104891748965653, 0.05524458744828265, 0.3008429817141518, 0.6892039217451478, 0.008204808592204139, 0.3758768523970982, 0.3913238463312256, 0.06693697371455175, 0.07208597169259419, 0.09268196360476395, 0.03898054308684685, 0.20789622979651654, 0.2338832585210811, 0.1559221723473874, 0.3508248877816217, 0.012993514362282283, 0.5234718747183759, 0.38948800202260103, 0.04362265622653132, 0.034274944177988896, 0.006231808032361617, 0.6926362197022492, 0.25052799436038803, 0.029473881689457415, 0.019649254459638277, 0.004912313614909569, 0.10450126321289598, 0.5834653862720025, 0.026125315803223994, 0.28737847383546394, 0.7885162153152245, 0.10426660698383135, 0.05864996642840513, 0.04561664055542621, 0.9716648622409658, 0.019292984629333255, 0.008769538467878753, 0.9765139976749342, 0.03393275474086268, 0.9161843780032923, 0.08562856988289444, 0.8905371267821023, 0.017125713976578888, 0.18646676642956853, 0.02071852960328539, 0.7665855953215595, 0.04143705920657078, 0.9781994721313632, 0.015049222648174817, 0.2726545902154431, 0.6517109717344737, 0.006650111956474222, 0.006650111956474222, 0.059851007608267996, 0.9758204783470219, 0.08041490182789189, 0.8845639201068107, 0.01148784311827027, 0.01148784311827027, 0.01148784311827027, 0.8693272429963537, 0.09659191588848373, 0.5608808923844598, 0.2804404461922299, 0.14164669165851174, 0.035411672914627934, 0.8144684770364425, 0.2068219135785701, 0.26949522072359133, 0.39484183501363385, 0.006267330714502125, 0.11907928357554036, 0.8043059091626803, 0.9341210109272854, 0.9361932507279808, 0.3181239725331557, 0.354630002168108, 0.1981755894468839, 0.04172117672565977, 0.07301205926990459, 0.010430294181414942, 0.8839888531334271, 0.48590031160449365, 0.32393354106966243, 0.8688268932814334, 0.10804161760849422, 0.08839768713422254, 0.7661132884965954, 0.029465895711407515, 0.175956284627052, 0.11965027354639536, 0.6862295100455028, 0.0175956284627052, 0.9892423987079237, 0.5728966896162055, 0.34373801376972335, 0.06669767263114149, 0.8114883503455548, 0.055581393859284574, 0.06669767263114149, 0.035772782007268265, 0.9479787231926091, 0.4993168834705832, 0.42798590011764276, 0.03057042143697448, 0.04076056191596598, 0.1734250405319141, 0.6937001621276564, 0.05780834684397137, 0.05780834684397137, 0.1968047771066092, 0.17448670959967413, 0.07304094820451475, 0.5498360267617638, 0.006086745683709563, 0.8778981812499093, 0.6516822879495924, 0.3258411439747962, 0.44763998281705736, 0.4616287322800904, 0.05595499785213217, 0.041966248389099126, 0.39078194155485396, 0.2930864561661405, 0.2930864561661405, 0.1253834405303444, 0.8463382235798247, 0.6585832321939858, 0.1492539902989203, 0.0970150936942982, 0.07462699514946015, 0.01865674878736504, 0.9672291577590308, 0.0210267208208485, 0.1316721317542587, 0.8690360695781075, 0.9159751831577353, 0.9539468362595876, 0.9921694595744434, 0.9525081945376088, 0.023518720852780464, 0.023518720852780464, 0.2235394956297511, 0.46223421130219716, 0.018944025053368736, 0.2803715707898573, 0.015155220042694989, 0.7991213561066648, 0.14753009651199964, 0.018441262063999955, 0.03688252412799991, 0.6878988556712268, 0.24913093691876861, 0.02231023315690465, 0.03718372192817442, 0.6427323463160172, 0.25709293852640686, 0.9441202727717477, 0.029503758524117116, 0.024298808441990942, 0.9719523376796377, 0.9364049639708552, 0.031213498799028506, 0.031213498799028506, 0.9668965454877659, 0.016114942424796098, 0.016114942424796098, 0.9023084713485319, 0.05156048407705897, 0.03867036305779423, 0.07121557149704379, 0.9258024294615692, 0.1508063871999154, 0.8378132622217522, 0.7598107530380492, 0.8367445795072457, 0.13050144818002915, 0.007676555775295832, 0.023029667325887494, 0.16844637684805988, 0.38426829718463656, 0.22634981888958045, 0.03158369565901122, 0.18950217395406735, 0.5525512652099479, 0.13594515255165385, 0.17979842756831638, 0.10524786003999008, 0.017541310006665013, 0.008770655003332507, 0.15435031367977567, 0.07717515683988783, 0.6945764115589905, 0.07717515683988783, 0.9260453121335694, 0.04409739581588426, 0.02210646468140591, 0.9726844459818601, 0.974400564942406, 0.3383578333687192, 0.618378109260073, 0.035002534486419226, 0.9580030609979852, 0.10852041655635424, 0.8681633324508339, 0.060963539971729534, 0.06858398246819573, 0.007620442496466192, 0.8611100021006797, 0.12323583524128759, 0.07170084959493096, 0.08290410734413892, 0.7058052382001017, 0.01568456084889115, 0.5059693478016214, 0.24188885487007336, 0.17975226829794444, 0.03328745709221193, 0.031068293286064468, 0.008876655224589847, 0.9448939042264031, 0.9598499589476708, 0.018458653056685977, 0.018458653056685977, 0.26848996031162364, 0.41589621303173074, 0.25796094226018745, 0.036851563180026775, 0.015793527077154333, 0.3856716096176262, 0.3856716096176262, 0.11570148288528785, 0.07713432192352523, 0.03856716096176262, 0.07713432192352523, 0.27886824814980704, 0.41830237222471056, 0.13943412407490352, 0.274727244377595, 0.013082249732266427, 0.7064414855423871, 0.013082249732266427, 0.03366589401587895, 0.016832947007939476, 0.9426450324446106, 0.9620468980783591, 0.028145944539993653, 0.5418094323948778, 0.24627701472494445, 0.03518243067499206, 0.14072972269996825, 0.007036486134998413, 0.1712612448933862, 0.5810649380311317, 0.14067887973385296, 0.058106493803113175, 0.04587354773929987, 0.2228726667218619, 0.5110700805863385, 0.15370528739438752, 0.08069527588205344, 0.023055793109158125, 0.007685264369719376, 0.07780889791946309, 0.0636618255704698, 0.8276037324161075, 0.014147072348993291, 0.014147072348993291, 0.5505598701523933, 0.19913867643809968, 0.023428079580952905, 0.155211027223813, 0.07028423874285872, 0.1923685994396766, 0.007124762942210245, 0.320614332399461, 0.47735911712808643, 0.44144263020016816, 0.3413480803291998, 0.17709035746402094, 0.033364849956989455, 0.005133053839536839, 0.9466796232798347, 0.43696601456545237, 0.21848300728272618, 0.21848300728272618, 0.07041972036994644, 0.5985676231445448, 0.05281479027745983, 0.28167888147978576, 0.3611842452646954, 0.4165482536629334, 0.11600077950107006, 0.07118229651202027, 0.031636576227564564, 0.0026363813522970467, 0.25493513249881705, 0.716774140648848, 0.02586298445640173, 0.04521339991066812, 0.3164937993746768, 0.6103808987940196, 0.1716659383789558, 0.3274857901383157, 0.060743332041784365, 0.21656318380114425, 0.21656318380114425, 0.00528202887319864, 0.889420326265147, 0.9535932321690735, 0.27232802786138915, 0.7262080742970378, 0.8833239393599644, 0.05888826262399763, 0.047110610099198105, 0.9785006438674348, 0.08035537598873202, 0.8839091358760522, 0.16087817953641398, 0.7239518079138628, 0.021523122618655608, 0.43046245237311215, 0.08609249047462243, 0.40893932975445657, 0.043046245237311216, 0.9112943236837356, 0.0059561720502204945, 0.07743023665286643, 0.0059561720502204945, 0.2927255857285702, 0.3469340275301573, 0.2428538192711101, 0.04119841576920618, 0.0758918185222219, 0.30774165802292086, 0.06154833160458417, 0.09232249740687626, 0.4923866528366734, 0.3900317624758866, 0.39467499774345666, 0.09750794061897165, 0.018572941070280315, 0.09286470535140157, 0.004643235267570079, 0.9776024227310618, 0.2660707604439697, 0.4761266239523669, 0.20655493244992384, 0.04551210376015272, 0.0035009310584732858, 0.23540437580240944, 0.5641587626988778, 0.08929131495953462, 0.020293480672621503, 0.08929131495953462, 0.19199174095241847, 0.35508149939587075, 0.30966409831035235, 0.08877037484896769, 0.05573953769586343, 0.5197277179123028, 0.35392501035745766, 0.12116351705930983, 0.003188513606823943, 0.0015942568034119716, 0.0015942568034119716, 0.033855683937660856, 0.033855683937660856, 0.8971756243480128, 0.016927841968830428, 0.3674253751406609, 0.4899005001875479, 0.06998578574107828, 0.01749644643526957, 0.03499289287053914, 0.9211408409322311, 0.03070469469774104, 0.06667776013810431, 0.666777601381043, 0.13335552027620862, 0.006061614558009482, 0.12729390571819912, 0.16034919694845345, 0.16034919694845345, 0.6413967877938138, 0.10924338455125503, 0.16022363067517403, 0.6700260919143641, 0.029131569213668006, 0.03641446151708501, 0.5582307613759627, 0.2746375938320244, 0.10448169330566147, 0.05373344227148304, 0.005970382474609227, 0.6730815265548515, 0.2692326106219406, 0.06839818033445345, 0.2735927213378138, 0.6839818033445345, 0.3129017632706183, 0.17880100758321046, 0.4470025189580262, 0.044700251895802616, 0.8921120972507797, 0.9059529478077802, 0.04467905960909045, 0.9084742120515059, 0.014893019869696817, 0.029786039739393633, 0.30761228720290573, 0.05028277771585959, 0.6388870580368042, 0.0918838884453793, 0.02625253955582266, 0.8663338053421478, 0.053898082529978936, 0.9162674030096419, 0.026949041264989468, 0.6316716557937179, 0.1263343311587436, 0.1263343311587436, 0.9765457412880426, 0.3935269294650239, 0.07560369580855139, 0.3373087966843062, 0.17059295464493646, 0.019385563027833688, 0.0019385563027833688, 0.13918540147263989, 0.7237640876577274, 0.08351124088358393, 0.009279026764842659, 0.05567416058905595, 0.04531082575967851, 0.8155948636742131, 0.07120272619378051, 0.006472975108525501, 0.058256775976729507, 0.006472975108525501, 0.31771806165917865, 0.3007730983706891, 0.3473717474140353, 0.004236240822122382, 0.008472481644244764, 0.02118120411061191, 0.9358728698403873, 0.034561832668200815, 0.8813267330391207, 0.06912366533640163, 0.06628291516618318, 0.9113900835350187, 0.9107434346465022, 0.08095497196857797, 0.010119371496072246, 0.08682037184006262, 0.7813833465605636, 0.08682037184006262, 0.9545011959013312, 0.7354696084363177, 0.3526887072075558, 0.11064743755531162, 0.03457732423603488, 0.4702516096100744, 0.013830929694413952, 0.013830929694413952, 0.9581457153739507, 0.05079265487184691, 0.9142677876932443, 0.8922486779523042, 0.05248521635013555, 0.9794748727148178, 0.974115220491743, 0.5859215803727599, 0.17755199405235148, 0.09173519692704826, 0.13020479563839107, 0.011836799603490098, 0.5948994688121438, 0.2974497344060719, 0.9679386810476006, 0.1089720534947734, 0.8717764279581872, 0.18320567958704986, 0.7411502492385199, 0.024982592670961343, 0.04163765445160224, 0.7443110858297463, 0.9632851333495621, 0.031583119126215156, 0.1933695545579301, 0.05252012592931435, 0.4846175256204915, 0.24588968048724444, 0.023872784513324703, 0.5000427193325001, 0.07542543811160617, 0.2514181270386872, 0.17040561943733246, 0.20130962623006982, 0.7123263697371701, 0.0619414234554061, 0.814321366311335, 0.11633162375876215, 0.05318309922486525, 0.9395680863059527, 0.03442340763723288, 0.01721170381861644, 0.9466437100239041, 0.05747381808232558, 0.36998770390497093, 0.5711460671931105, 0.08610995054501841, 0.8610995054501841, 0.028703316848339468, 0.12907805062618563, 0.45894418000421555, 0.21513008437697603, 0.07171002812565869, 0.08605203375079042, 0.028684011250263472, 0.4928185337469063, 0.12915244332677545, 0.3772610844545283, 0.39481202850030034, 0.04268238145949193, 0.554870958973395, 0.005335297682436491, 0.7617293319551965, 0.20384306066406668, 0.010728582140214037, 0.021457164280428074, 0.10889107492237451, 0.8018342789738486, 0.019798377258613546, 0.04949594314653387, 0.019798377258613546, 0.006515095980990845, 0.9902945891106084, 0.006515095980990845, 0.01852664415930219, 0.963385496283714, 0.06854320126181886, 0.017135800315454714, 0.8910616164036452, 0.017135800315454714, 0.2663266898279366, 0.48261624399123054, 0.11137297938259166, 0.08554736097503418, 0.050037135664642636, 0.004842303451417029, 0.33730317335817095, 0.4216289666977137, 0.16865158667908547, 0.08432579333954274, 0.955601769217233, 0.027311395671135368, 0.2287329387457587, 0.3243228235947325, 0.38577346385478706, 0.03413924458891921, 0.07813933738941019, 0.21752302030024998, 0.4751716462869538, 0.1689499186798058, 0.05913247153793203, 0.5304748003383949, 0.26523740016919745, 0.06630935004229936, 0.13261870008459872, 0.2773301313209767, 0.33215120379140234, 0.06127061040812276, 0.3257016658537052, 0.0032247689688485663, 0.1311426179960466, 0.20982818879367454, 0.20781061005527382, 0.3974630114649412, 0.052457047198418635, 0.3483188104216992, 0.11057740013387277, 0.45889621055557195, 0.011057740013387276, 0.06634644008032366, 0.005528870006693638, 0.1906108291828354, 0.14194423449785615, 0.5353325415347717, 0.13383313538369293, 0.4875427633609398, 0.0769804363201484, 0.2790540816605379, 0.1539608726402968, 0.003207518180006183, 0.00825729400998943, 0.03302917603995772, 0.3344204074045719, 0.5780105806992601, 0.04541511705494187, 0.057448119699235675, 0.09335319451125797, 0.4093178528570542, 0.06821964214284236, 0.36982227056382966, 0.9633473908203515, 0.9581064255943121, 0.944586334536802, 0.030470526920541998, 0.1086558699870233, 0.01552226714100333, 0.8537246927551831, 0.007761133570501665, 0.49923491021797567, 0.34946443715258296, 0.09984698204359514, 0.3618999560973253, 0.5428499341459879, 0.12063331869910844, 0.5295975357272281, 0.08998016383715042, 0.2905073861027999, 0.08998016383715042, 0.9874201199437165, 0.12954754895755452, 0.8636503263836969, 0.02159125815959242, 0.45430612951053495, 0.2523922941725194, 0.15143537650351163, 0.01376685240941015, 0.12849062248782805, 0.39060870797769653, 0.06510145132961609, 0.5208116106369287, 0.24798814447971235, 0.6199703611992808, 0.9874700103106262, 0.9773398502748478, 0.04355539071139061, 0.3484431256911249, 0.4355539071139061, 0.08711078142278122, 0.08711078142278122, 0.2697538477592257, 0.2697538477592257, 0.41961709651435103, 0.059945299502050145, 0.9386602397486323, 0.19402356495884038, 0.10977649070039652, 0.13530590714234922, 0.5463295118577873, 0.012764708220976341, 0.06583474652350359, 0.9216864513290502, 0.9226923946525535, 0.06307895712301977, 0.01576973928075494, 0.20500661064981424, 0.7175231372743499, 0.17750983221583258, 0.8185175596618947, 0.39894750186476696, 0.08716500040742808, 0.4090050019117779, 0.09722250045443902, 0.010057500047010932, 0.1774791255641496, 0.7099165022565984, 0.010454204627080035, 0.20908409254160074, 0.18817568328744064, 0.010454204627080035, 0.5645270498623219, 0.010454204627080035, 0.9541550398033958, 0.8046624118999794, 0.17881386931110654, 0.053915903595860744, 0.943528312927563, 0.9863231997107891, 0.2635248542871314, 0.6588121357178285, 0.9163040883962703, 0.06430204129096634, 0.016075510322741585, 0.43672171407557864, 0.21836085703778932, 0.21836085703778932, 0.10918042851889466, 0.4960008713829531, 0.19840034855318125, 0.2314670733120448, 0.03306672475886354, 0.7377024238400456, 0.14754048476800913, 0.4455248777605434, 0.2830393341066982, 0.22014170430520968, 0.03406954947580626, 0.01048293830024808, 0.00524146915012404, 0.44960175045649026, 0.31693238146932917, 0.1289841087375177, 0.04422312299572035, 0.03685260249643363, 0.022111561497860175, 0.9141133237061753, 0.9229402350045541, 0.026369721000130117, 0.026369721000130117], \"Term\": [\"able\", \"able\", \"able\", \"able\", \"able\", \"accountabilities\", \"accountabilities\", \"accountabilities\", \"accountabilities\", \"accounting\", \"across\", \"across\", \"across\", \"across\", \"activities\", \"activities\", \"activities\", \"activities\", \"activities\", \"activities\", \"actual\", \"actual\", \"adjustments\", \"adjustments\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advances\", \"advances\", \"advances\", \"advertising\", \"aggregate\", \"aggregate\", \"aggregate\", \"agile\", \"agile\", \"alerts\", \"algorithms\", \"algorithms\", \"algorithms\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytical\", \"analytics\", \"analytics\", \"analytics\", \"analytics\", \"apis\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"assay\", \"assay\", \"assays\", \"assays\", \"assays\", \"assurance\", \"assurance\", \"assurance\", \"assurance\", \"assurance\", \"attending\", \"audio\", \"audio\", \"autism\", \"autonomous\", \"autonomous\", \"autonomous\", \"based\", \"based\", \"based\", \"based\", \"based\", \"benchmarking\", \"benchmarking\", \"benchmarking\", \"biology\", \"biology\", \"biology\", \"biopharmaceutical\", \"biotechnology\", \"book\", \"brand\", \"brand\", \"bsc\", \"bsc\", \"bsc\", \"budget\", \"budget\", \"build\", \"build\", \"build\", \"build\", \"calibration\", \"calibration\", \"campaign\", \"campaigns\", \"campaigns\", \"cancer\", \"cancer\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"capa\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carnegie\", \"cell\", \"cell\", \"cell\", \"cgmp\", \"cgmp\", \"chemistry\", \"chemistry\", \"chromatography\", \"chromatography\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"classified\", \"cleansing\", \"clearance\", \"clearance\", \"client\", \"client\", \"client\", \"client\", \"client\", \"clients\", \"clients\", \"clients\", \"clients\", \"clinical\", \"clinical\", \"clinical\", \"cloud\", \"cloud\", \"come\", \"come\", \"communicates\", \"communicates\", \"communicates\", \"communicates\", \"communications\", \"communications\", \"communications\", \"communications\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"compliance\", \"compliance\", \"compliance\", \"compliance\", \"compliance\", \"computational\", \"computational\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computing\", \"computing\", \"confidence\", \"confidence\", \"confidence\", \"confidential\", \"confidential\", \"confidentiality\", \"confidentiality\", \"confidentiality\", \"confidentiality\", \"consensus\", \"consensus\", \"consensus\", \"consulting\", \"consulting\", \"consulting\", \"consulting\", \"content\", \"content\", \"content\", \"contract\", \"contract\", \"contract\", \"contract\", \"contract\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"coordination\", \"cra\", \"crm\", \"crm\", \"crm\", \"cro\", \"curious\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customers\", \"customers\", \"customers\", \"customers\", \"customers\", \"customers\", \"cutting\", \"cutting\", \"cutting\", \"cyber\", \"cycles\", \"daily\", \"daily\", \"daily\", \"daily\", \"daily\", \"daily\", \"dates\", \"dates\", \"dates\", \"demand\", \"demand\", \"demand\", \"demonstrable\", \"demonstrable\", \"design\", \"design\", \"design\", \"design\", \"design\", \"desirable\", \"desirable\", \"desirable\", \"desirable\", \"desirable\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"developer\", \"developer\", \"developments\", \"developments\", \"developments\", \"developments\", \"deviation\", \"digital\", \"digital\", \"digital\", \"discuss\", \"discuss\", \"discuss\", \"disease\", \"display\", \"dna\", \"drug\", \"drug\", \"drug\", \"drug\", \"drug\", \"effectively\", \"effectively\", \"effectively\", \"effectively\", \"effectively\", \"effectively\", \"electrical\", \"electrical\", \"elisa\", \"elisa\", \"email\", \"email\", \"email\", \"employ\", \"employ\", \"end\", \"end\", \"end\", \"end\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"engineering\", \"ensure\", \"ensure\", \"ensure\", \"ensure\", \"ensure\", \"ensure\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environmental\", \"environmental\", \"environments\", \"environments\", \"environments\", \"environments\", \"equipment\", \"equipment\", \"equipment\", \"equipment\", \"equipment\", \"etl\", \"etl\", \"exceptionally\", \"exceptionally\", \"exceptionally\", \"exceptionally\", \"experimental\", \"experimental\", \"experimental\", \"expertise\", \"expertise\", \"expertise\", \"expertise\", \"expertise\", \"expertise\", \"extend\", \"extend\", \"extend\", \"financial\", \"financial\", \"financial\", \"financial\", \"finished\", \"firewalls\", \"followed\", \"followed\", \"forests\", \"frequently\", \"frequently\", \"frequently\", \"friday\", \"friday\", \"friday\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"fundraising\", \"future\", \"future\", \"future\", \"future\", \"future\", \"gap\", \"gcp\", \"generous\", \"genetics\", \"genome\", \"gives\", \"gmp\", \"gmp\", \"good\", \"good\", \"good\", \"good\", \"good\", \"google\", \"google\", \"great\", \"great\", \"great\", \"health\", \"health\", \"health\", \"health\", \"health\", \"help\", \"help\", \"help\", \"help\", \"hidden\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"highly\", \"hit\", \"hplc\", \"hub\", \"ich\", \"image\", \"image\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"improve\", \"improve\", \"improve\", \"improve\", \"industry\", \"industry\", \"industry\", \"industry\", \"industry\", \"informatica\", \"insights\", \"insights\", \"insights\", \"insights\", \"installing\", \"instrument\", \"instrument\", \"instrumentation\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interacting\", \"interacting\", \"interacting\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interest\", \"interest\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internally\", \"internally\", \"internally\", \"intervention\", \"intervention\", \"investigations\", \"investigations\", \"investigations\", \"investigator\", \"iso\", \"iso\", \"java\", \"java\", \"java\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"keeping\", \"keeping\", \"kind\", \"laboratory\", \"laboratory\", \"laboratory\", \"laboratory\", \"laboratory\", \"language\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"latency\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"like\", \"like\", \"like\", \"logistic\", \"looking\", \"looking\", \"looking\", \"looking\", \"low\", \"low\", \"low\", \"low\", \"machine\", \"machine\", \"machine\", \"maintain\", \"maintain\", \"maintain\", \"maintain\", \"maintain\", \"maintenance\", \"maintenance\", \"maintenance\", \"maintenance\", \"maintenance\", \"maintenance\", \"manage\", \"manage\", \"manage\", \"manage\", \"manage\", \"manager\", \"manager\", \"manager\", \"manager\", \"manager\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"manufacturing\", \"market\", \"market\", \"market\", \"market\", \"marketing\", \"marketing\", \"marketing\", \"marlborough\", \"mathematical\", \"mathematical\", \"matlab\", \"matlab\", \"matlab\", \"matter\", \"matter\", \"matter\", \"matter\", \"media\", \"media\", \"medical\", \"medical\", \"medical\", \"medical\", \"medical\", \"medicine\", \"meetings\", \"meetings\", \"meetings\", \"meetings\", \"meetings\", \"metabolic\", \"metabolic\", \"metabolism\", \"metabolism\", \"method\", \"method\", \"method\", \"methods\", \"methods\", \"methods\", \"methods\", \"methods\", \"metric\", \"microbiology\", \"million\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"mitigation\", \"mix\", \"mix\", \"mixed\", \"model\", \"model\", \"model\", \"model\", \"models\", \"models\", \"models\", \"models\", \"molecular\", \"monday\", \"monday\", \"monitoring\", \"monitoring\", \"monitoring\", \"monitoring\", \"monitors\", \"monitors\", \"motivated\", \"motivated\", \"motivated\", \"motivated\", \"multitask\", \"multitask\", \"multitask\", \"multitask\", \"must\", \"must\", \"must\", \"must\", \"must\", \"naive\", \"nature\", \"nature\", \"necessary\", \"necessary\", \"necessary\", \"necessary\", \"net\", \"net\", \"net\", \"neural\", \"neural\", \"new\", \"new\", \"new\", \"new\", \"new\", \"ngs\", \"ngs\", \"nlp\", \"nlp\", \"numerical\", \"nursing\", \"oncology\", \"online\", \"online\", \"online\", \"operations\", \"operations\", \"operations\", \"operations\", \"operations\", \"opportunities\", \"opportunities\", \"opportunities\", \"opportunities\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"optimal\", \"optimal\", \"options\", \"options\", \"oracle\", \"oracle\", \"outreach\", \"outreach\", \"outreach\", \"paid\", \"paid\", \"paid\", \"passion\", \"passion\", \"passion\", \"patient\", \"patient\", \"patients\", \"patients\", \"penetration\", \"people\", \"people\", \"people\", \"people\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performed\", \"performed\", \"performed\", \"performed\", \"perl\", \"perl\", \"pfizer\", \"pfizer\", \"pharma\", \"pharmaceutical\", \"pharmaceutical\", \"pharmaceutical\", \"pharmacology\", \"physics\", \"physics\", \"player\", \"player\", \"player\", \"player\", \"plus\", \"plus\", \"plus\", \"plus\", \"plus\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"ppc\", \"predictive\", \"predictive\", \"predictive\", \"preferred\", \"preferred\", \"preferred\", \"preferred\", \"preferred\", \"pressure\", \"pressure\", \"pressure\", \"pressure\", \"pressure\", \"pressure\", \"price\", \"price\", \"price\", \"pricing\", \"pricing\", \"pricing\", \"pricing\", \"primarily\", \"primarily\", \"primarily\", \"print\", \"procedures\", \"procedures\", \"procedures\", \"procedures\", \"procedures\", \"procedures\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processes\", \"processes\", \"processes\", \"processes\", \"processes\", \"processes\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"product\", \"product\", \"product\", \"product\", \"product\", \"programming\", \"programming\", \"programming\", \"programming\", \"projects\", \"projects\", \"projects\", \"projects\", \"projects\", \"prospects\", \"protect\", \"protect\", \"protect\", \"protocols\", \"protocols\", \"protocols\", \"protocols\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"python\", \"python\", \"python\", \"qualification\", \"qualification\", \"qualification\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quant\", \"reach\", \"reagent\", \"reagent\", \"real\", \"real\", \"real\", \"recommending\", \"regression\", \"regression\", \"regulated\", \"regulated\", \"regulations\", \"regulations\", \"regulations\", \"regulations\", \"regulations\", \"regulatory\", \"regulatory\", \"regulatory\", \"regulatory\", \"related\", \"related\", \"related\", \"related\", \"related\", \"release\", \"release\", \"release\", \"release\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relevant\", \"relocation\", \"reporting\", \"reporting\", \"reporting\", \"reporting\", \"reporting\", \"reports\", \"reports\", \"reports\", \"reports\", \"reports\", \"requirements\", \"requirements\", \"requirements\", \"requirements\", \"requirements\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"resolving\", \"resolving\", \"resolving\", \"resolving\", \"responsibility\", \"responsibility\", \"responsibility\", \"responsibility\", \"responsibility\", \"revenue\", \"revenue\", \"review\", \"review\", \"review\", \"review\", \"review\", \"revise\", \"revise\", \"revise\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"role\", \"role\", \"role\", \"role\", \"role\", \"room\", \"room\", \"root\", \"root\", \"root\", \"routine\", \"routine\", \"routine\", \"routine\", \"runs\", \"saas\", \"safety\", \"safety\", \"safety\", \"safety\", \"sales\", \"sales\", \"sales\", \"salesforce\", \"salesforce\", \"salesforce\", \"scala\", \"scala\", \"scala\", \"scheduled\", \"scheduled\", \"scheduled\", \"school\", \"science\", \"science\", \"science\", \"science\", \"science\", \"science\", \"sciences\", \"sciences\", \"sciences\", \"sciences\", \"sciences\", \"scientific\", \"scientific\", \"scientific\", \"scientific\", \"scientific\", \"scientific\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scientist\", \"scikit\", \"scripting\", \"scripting\", \"scripting\", \"sdlc\", \"sdlc\", \"search\", \"search\", \"search\", \"secondary\", \"secondary\", \"secondary\", \"segmentation\", \"select\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"sem\", \"sensing\", \"sensing\", \"sensor\", \"sensor\", \"seo\", \"server\", \"services\", \"services\", \"services\", \"services\", \"services\", \"sheets\", \"sheets\", \"signal\", \"simulation\", \"simulation\", \"site\", \"site\", \"site\", \"site\", \"smes\", \"social\", \"social\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solutions\", \"solutions\", \"solutions\", \"solutions\", \"spark\", \"spark\", \"spark\", \"specified\", \"specified\", \"spend\", \"spend\", \"sponsorship\", \"sponsorship\", \"sponsorship\", \"sql\", \"sql\", \"sql\", \"stability\", \"stability\", \"stability\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"standard\", \"statistical\", \"statistical\", \"statistical\", \"statistics\", \"statistics\", \"statistics\", \"statistics\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"studies\", \"studies\", \"studies\", \"studies\", \"studies\", \"study\", \"study\", \"study\", \"subversion\", \"subversion\", \"summaries\", \"summaries\", \"summaries\", \"summaries\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"surface\", \"surface\", \"surface\", \"surface\", \"survey\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"systems\", \"systems\", \"systems\", \"systems\", \"takes\", \"takes\", \"takes\", \"takes\", \"teams\", \"teams\", \"teams\", \"teams\", \"teams\", \"technical\", \"technical\", \"technical\", \"technical\", \"technical\", \"techniques\", \"techniques\", \"techniques\", \"techniques\", \"techniques\", \"techniques\", \"technologies\", \"technologies\", \"technologies\", \"technologies\", \"technology\", \"technology\", \"technology\", \"technology\", \"technology\", \"test\", \"test\", \"test\", \"test\", \"test\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"therapeutic\", \"therapeutics\", \"things\", \"things\", \"thorough\", \"thorough\", \"thorough\", \"thorough\", \"throughput\", \"throughput\", \"throughput\", \"tight\", \"tight\", \"tight\", \"tools\", \"tools\", \"tools\", \"tools\", \"toxicology\", \"trading\", \"trading\", \"trading\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trend\", \"trend\", \"trend\", \"trending\", \"trending\", \"trial\", \"trials\", \"troubleshoot\", \"troubleshoot\", \"troubleshoot\", \"troubleshoot\", \"troubleshoot\", \"troubleshooting\", \"troubleshooting\", \"troubleshooting\", \"troubleshooting\", \"uat\", \"understanding\", \"understanding\", \"understanding\", \"understanding\", \"understanding\", \"unsupervised\", \"unsupervised\", \"upgrades\", \"user\", \"user\", \"user\", \"user\", \"users\", \"users\", \"using\", \"using\", \"using\", \"using\", \"using\", \"usp\", \"usp\", \"validation\", \"validation\", \"validation\", \"validation\", \"validation\", \"validation\", \"variant\", \"vitro\", \"vitro\", \"warehouse\", \"warehouse\", \"warehousing\", \"water\", \"water\", \"website\", \"website\", \"website\", \"weekend\", \"weekend\", \"weekend\", \"weekend\", \"weekly\", \"weekly\", \"weekly\", \"weekly\", \"weeks\", \"weeks\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"within\", \"within\", \"within\", \"within\", \"within\", \"within\", \"workshops\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 2, 5, 1, 7, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el138346689721522745953586\", ldavis_el138346689721522745953586_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el138346689721522745953586\", ldavis_el138346689721522745953586_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el138346689721522745953586\", ldavis_el138346689721522745953586_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "5      41.300480        1       1  0.008188  0.096902\n",
       "1      27.811512        1       2 -0.052106 -0.012517\n",
       "4      15.698070        1       3  0.103882 -0.042956\n",
       "0      11.715420        1       4  0.228572 -0.007350\n",
       "6       2.971612        1       5 -0.099935 -0.190476\n",
       "2       0.412130        1       6 -0.106353  0.061192\n",
       "3       0.090775        1       7 -0.082249  0.095205, topic_info=     Category        Freq             Term       Total  loglift  logprob\n",
       "term                                                                    \n",
       "1442  Default  361.000000      informatica  361.000000  30.0000  30.0000\n",
       "2297  Default  378.000000          quality  378.000000  29.0000  29.0000\n",
       "1333  Default  362.000000             high  362.000000  28.0000  28.0000\n",
       "3107  Default  271.000000           within  271.000000  27.0000  27.0000\n",
       "2859  Default  278.000000          testing  278.000000  26.0000  26.0000\n",
       "2793  Default  619.000000          support  619.000000  25.0000  25.0000\n",
       "2107  Default  446.000000             plus  446.000000  24.0000  24.0000\n",
       "475   Default  472.000000         clinical  472.000000  23.0000  23.0000\n",
       "2527  Default  236.000000        scientist  236.000000  22.0000  22.0000\n",
       "2117  Default  450.000000         position  450.000000  21.0000  21.0000\n",
       "148   Default  306.000000       analytical  306.000000  20.0000  20.0000\n",
       "1     Default  203.000000             able  203.000000  19.0000  19.0000\n",
       "1612  Default  497.000000         learning  497.000000  18.0000  18.0000\n",
       "1856  Default  492.000000             must  492.000000  17.0000  17.0000\n",
       "2496  Default  338.000000            sales  338.000000  16.0000  16.0000\n",
       "547   Default   89.000000     compensation   89.000000  15.0000  15.0000\n",
       "1038  Default  230.000000              etl  230.000000  14.0000  14.0000\n",
       "799   Default  529.000000           design  529.000000  13.0000  13.0000\n",
       "1687  Default  365.000000          machine  365.000000  12.0000  12.0000\n",
       "2842  Default  495.000000        technical  495.000000  11.0000  11.0000\n",
       "2809  Default  473.000000          systems  473.000000  10.0000  10.0000\n",
       "387   Default  302.000000        candidate  302.000000   9.0000   9.0000\n",
       "1959  Default  205.000000           oracle  205.000000   8.0000   8.0000\n",
       "1727  Default  570.000000        marketing  570.000000   7.0000   7.0000\n",
       "2379  Default  461.000000          related  461.000000   6.0000   6.0000\n",
       "2971  Default  391.000000    understanding  391.000000   5.0000   5.0000\n",
       "1585  Default  122.000000       laboratory  122.000000   4.0000   4.0000\n",
       "1402  Default  172.000000          improve  172.000000   3.0000   3.0000\n",
       "1014  Default  431.000000      environment  431.000000   2.0000   2.0000\n",
       "144   Default  742.000000         analysis  742.000000   1.0000   1.0000\n",
       "...       ...         ...              ...         ...      ...      ...\n",
       "547    Topic7    1.308818     compensation   89.336702   2.7812  -4.4798\n",
       "1835   Topic7    0.122254           monday    8.727577   2.7364  -6.8505\n",
       "341    Topic7    0.094921             book    6.777331   2.7362  -7.1036\n",
       "3088   Topic7    0.127064          weekend    9.159151   2.7267  -6.8119\n",
       "2454   Topic7    0.451549          revenue   32.568309   2.7261  -5.5440\n",
       "1471   Topic7    0.034188       installing    2.631395   2.6611  -8.1248\n",
       "1343   Topic7    0.033752              hit    2.598448   2.6609  -8.1376\n",
       "3090   Topic7    0.087611            weeks    6.777801   2.6560  -7.1837\n",
       "113    Topic7    0.034030           alerts    2.639585   2.6534  -8.1294\n",
       "2046   Topic7    0.033746      penetration    2.632234   2.6478  -8.1378\n",
       "1159   Topic7    0.033712        firewalls    2.658884   2.6367  -8.1388\n",
       "2638   Topic7    0.033675             smes    2.687049   2.6251  -8.1399\n",
       "1264   Topic7    0.033781            gives    2.698803   2.6239  -8.1367\n",
       "2560   Topic7    0.033931           select    2.719351   2.6207  -8.1323\n",
       "3121   Topic7    0.079718        workshops    7.657694   2.4396  -7.2781\n",
       "1952   Topic7    0.079636          optimal    7.779288   2.4228  -7.2792\n",
       "599    Topic7    0.100241  confidentiality   10.514146   2.3516  -7.0491\n",
       "1212   Topic7    0.090801           friday   10.349739   2.2685  -7.1480\n",
       "304    Topic7    0.084378     benchmarking   10.675773   2.1641  -7.2213\n",
       "3089   Topic7    0.154159           weekly   30.241882   1.7255  -6.6187\n",
       "2546   Topic7    0.081195        secondary   11.518034   2.0497  -7.2598\n",
       "1865   Topic7    0.079288           nature   12.275921   1.9622  -7.2835\n",
       "1870   Topic7    0.186059        necessary   71.486018   1.0533  -6.4306\n",
       "596    Topic7    0.165752       confidence   56.874184   1.1664  -6.5461\n",
       "772    Topic7    0.129820           demand   64.884527   0.7903  -6.7905\n",
       "733    Topic7    0.118899            daily   50.508919   0.9529  -6.8784\n",
       "1877   Topic7    0.098120              net   20.471775   1.6639  -7.0705\n",
       "2456   Topic7    0.146766           review  164.972548  -0.0202  -6.6678\n",
       "1694   Topic7    0.134758         maintain  194.212545  -0.2687  -6.7532\n",
       "1233   Topic7    0.116635           future   75.418568   0.5328  -6.8976\n",
       "\n",
       "[485 rows x 6 columns], token_table=      Topic      Freq              Term\n",
       "term                                   \n",
       "1         1  0.407945              able\n",
       "1         2  0.304730              able\n",
       "1         3  0.216260              able\n",
       "1         4  0.044235              able\n",
       "1         6  0.024575              able\n",
       "18        1  0.342073  accountabilities\n",
       "18        2  0.427592  accountabilities\n",
       "18        3  0.085518  accountabilities\n",
       "18        6  0.085518  accountabilities\n",
       "21        2  0.985258        accounting\n",
       "34        1  0.658565            across\n",
       "34        2  0.225662            across\n",
       "34        3  0.064475            across\n",
       "34        4  0.046054            across\n",
       "43        1  0.156924        activities\n",
       "43        2  0.636412        activities\n",
       "43        3  0.117693        activities\n",
       "43        4  0.008718        activities\n",
       "43        5  0.074103        activities\n",
       "43        6  0.004359        activities\n",
       "46        2  0.736007            actual\n",
       "46        4  0.122668            actual\n",
       "67        1  0.533916       adjustments\n",
       "67        2  0.400437       adjustments\n",
       "76        1  0.351355          advanced\n",
       "76        2  0.140542          advanced\n",
       "76        3  0.481086          advanced\n",
       "76        4  0.021622          advanced\n",
       "76        5  0.005405          advanced\n",
       "78        2  0.653578          advances\n",
       "...     ...       ...               ...\n",
       "3077      5  0.658812             water\n",
       "3085      1  0.916304           website\n",
       "3085      2  0.064302           website\n",
       "3085      4  0.016076           website\n",
       "3088      1  0.436722           weekend\n",
       "3088      2  0.218361           weekend\n",
       "3088      3  0.218361           weekend\n",
       "3088      5  0.109180           weekend\n",
       "3089      1  0.496001            weekly\n",
       "3089      2  0.198400            weekly\n",
       "3089      3  0.231467            weekly\n",
       "3089      4  0.033067            weekly\n",
       "3090      1  0.737702             weeks\n",
       "3090      2  0.147540             weeks\n",
       "3094      1  0.445525              well\n",
       "3094      2  0.283039              well\n",
       "3094      3  0.220142              well\n",
       "3094      4  0.034070              well\n",
       "3094      5  0.010483              well\n",
       "3094      6  0.005241              well\n",
       "3107      1  0.449602            within\n",
       "3107      2  0.316932            within\n",
       "3107      3  0.128984            within\n",
       "3107      4  0.044223            within\n",
       "3107      5  0.036853            within\n",
       "3107      6  0.022112            within\n",
       "3121      1  0.914113         workshops\n",
       "3134      1  0.922940              york\n",
       "3134      3  0.026370              york\n",
       "3134      4  0.026370              york\n",
       "\n",
       "[1244 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 2, 5, 1, 7, 3, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda_tf, dtm, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Income-Level\n",
    "\n",
    "As we have three income levels, the majority class rate is the baseline. 40% of the postings in the dataframe are in the 80K-115K per year range. If we guessed that each posting was at this income-level, we would be correct 40% of the time. Thus, the goal of our classifier is to beat this number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting categories to labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "scraped_postings['category'] = le.fit_transform(scraped_postings['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39781591263650545"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#income-level baseline\n",
    "mask = scraped_postings['category'] == 2\n",
    "float(len(scraped_postings[mask])) / scraped_postings.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting 3-fold cross-validation, we first notice substantial spread in the results of the Logistic Regression, likely indicative of having more than an ideal number of features. That being said, even the lowest score yielded by cross-validation is nearly 50% more accurate than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59069767  0.657277    0.65258216]\n"
     ]
    }
   ],
   "source": [
    "cvt = CountVectorizer(stop_words=english, ngram_range=(1,2))\n",
    "X_all = cvt.fit_transform(scraped_postings['summary'])\n",
    "y = scraped_postings['category']\n",
    "print(cross_val_score(LogisticRegression(), X_all, y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the regression on 80% of the posting data yields accurate predictions in 69% of cases. That's an awfully impressive lift of 1.77 (69/39) relative to the baseline. My sense is that the score on the testing split is higher than in cross validation because the classifier was fit on a larger sample of data. It's worth nothing that this result was acheived purely with default parameters and could very likely be improved through grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = scraped_postings['summary'] \n",
    "y = scraped_postings['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68992248062015504"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt = CountVectorizer(stop_words=english,  ngram_range=(1,2))\n",
    "pipeline = Pipeline([\n",
    "    ('vect', cvt),\n",
    "#    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', LogisticRegression())\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows that the classifier worked fairly similarly with each income-class. Precision at 2/3 or better demonstrates that classifications were 2/3 or more likely to be correct. There is more disparity in recall: the majority of the total lowest income-tier postings were classified as such but that number is just under 2/3 for the other income classes. At a high level, the classifier did the best job classifying the lowest income-jobs and, relatively speaking, did the worst classifying the middle-tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       120+       0.73      0.65      0.69        34\n",
      "        <75       0.67      0.82      0.74        39\n",
      "     80-115       0.69      0.62      0.65        56\n",
      "\n",
      "avg / total       0.69      0.69      0.69       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted, target_names=[ \"120+\", \"<75\", \"80-115\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Predictors - Income\n",
    "\n",
    "Logistic regression provides additional insight about what differentiates the highest income jobs in the dataset via it’s coefficient output. Though data science jobs represent less than 20% of the collected postings, they are disproportionately concentrated in the high salary tiers, and the best predictors of high salary positions are, in order: “machine learning,” “big data,” and “data science.” The feature occurring in multiple forms negatively predicting high-wage work in the sample: a bachelor’s degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = cvt.fit_transform(scraped_postings['summary'])\n",
    "y = scraped_postings['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "#lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine learning</th>\n",
       "      <td>0.397822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big data</th>\n",
       "      <td>0.224195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science</th>\n",
       "      <td>0.212678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep learning</th>\n",
       "      <td>0.205199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 00</th>\n",
       "      <td>0.175656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing cloud</th>\n",
       "      <td>0.121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 00 year</th>\n",
       "      <td>0.117096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data mining</th>\n",
       "      <td>0.113404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientists</th>\n",
       "      <td>0.113225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      coef\n",
       "machine learning  0.397822\n",
       "big data          0.224195\n",
       "data science      0.212678\n",
       "deep learning     0.205199\n",
       "000 00            0.175656\n",
       "marketing cloud   0.121114\n",
       "000 00 year       0.117096\n",
       "data mining       0.113404\n",
       "data scientists   0.113225"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(cvt.get_feature_names())\n",
    "lr_coefs = pd.DataFrame({'coef':lr.coef_[0]},index=features)\n",
    "lr_coefs = lr_coefs.sort_values('coef',ascending=False)\n",
    "lr_coefs.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type full</th>\n",
       "      <td>-0.261128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type full time</th>\n",
       "      <td>-0.261128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bachelor degree</th>\n",
       "      <td>-0.292407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full time</th>\n",
       "      <td>-0.329437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education bachelor</th>\n",
       "      <td>-0.344268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        coef\n",
       "type full          -0.261128\n",
       "type full time     -0.261128\n",
       "bachelor degree    -0.292407\n",
       "full time          -0.329437\n",
       "education bachelor -0.344268"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coefs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterizing Job Postings by Income-Tier\n",
    "\n",
    "Though the word counts were better predictors for the classifier than the term weights, I think the term weights offer more intuitive insight. Looking at the postings by income-tier reveals that \"marketing\" has the highest term-weight for the < 75K per year postings. \"Research\" and \"support\" also stick out for this tier, the latter term perhaps contrasting with the salience of \"development\" and \"design\" in higher income tiers. The middle-income tier uniquely prizes \"analysis\" and, like the highest tier, has a larger weight for data than the sub-75 tier. The highest income-tier seems to be disproportionately populated by data science roles, yielding \"machine learning\" and \"analytics\" in the list of top 10 term weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketing     4.917930\n",
       "data          3.265247\n",
       "skills        2.947199\n",
       "sales         2.692812\n",
       "ability       2.606512\n",
       "management    2.575037\n",
       "clinical      2.549105\n",
       "team          2.505177\n",
       "support       2.484247\n",
       "research      2.190723\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = scraped_postings['category'] == 1 ##1 corresponds to < 75K per year\n",
    "tfidf = TfidfVectorizer(stop_words=english, ngram_range=(1,4))\n",
    "X_all = tfidf.fit_transform(scraped_postings.ix[mask,'summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           6.683377\n",
       "development    4.128827\n",
       "skills         3.524531\n",
       "analysis       3.149571\n",
       "team           3.052998\n",
       "software       3.045155\n",
       "clinical       3.021502\n",
       "ability        2.778972\n",
       "systems        2.700767\n",
       "strong         2.667731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = scraped_postings['category'] == 2\n",
    "tfidf = TfidfVectorizer(stop_words=english, ngram_range=(1,4))\n",
    "X_all = tfidf.fit_transform(scraped_postings.ix[mask,'summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                6.820855\n",
       "learning            3.341324\n",
       "development         2.921638\n",
       "machine             2.541522\n",
       "machine learning    2.526492\n",
       "team                2.439990\n",
       "management          2.407016\n",
       "analytics           2.374114\n",
       "skills              2.366834\n",
       "design              2.218176\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = scraped_postings['category'] == 0\n",
    "tfidf = TfidfVectorizer(stop_words=english, ngram_range=(1,4))\n",
    "X_all = tfidf.fit_transform(scraped_postings.ix[mask,'summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAFJCAYAAACimpYTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wBi7BW1+DODKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130f7b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fw = freq_words[:10]\n",
    "fw.plot(kind='barh')\n",
    "#sns.countplot(x=lr.index, data=lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data Science Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second prompt, classifying data science jobs, boosted decision trees turn out to be a better classifier than logisitic regression. Whereas the latter classifier roughly achieves the baseline of 82% accuracy - here meaning a guess that each posting in our simple does not represent a data science job - we generate a lift of 1.13 using boosted decision trees with default parameters and simple word count. As above, the abundance of features and small cross validation sizes yield significant spread in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8159126365054602"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds_jobs baseline\n",
    "mask = scraped_postings['ds_job'] == 1\n",
    "1- (float(len(scraped_postings[mask])) / scraped_postings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93023256  0.89671362  0.85915493]\n"
     ]
    }
   ],
   "source": [
    "X_all = cvt.fit_transform(scraped_postings['summary'])\n",
    "y = scraped_postings['ds_job']\n",
    "print(cross_val_score(AdaBoostClassifier(), X_all, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = scraped_postings['summary']\n",
    "y = scraped_postings['ds_job']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92248062015503873"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt = CountVectorizer(stop_words=english,  ngram_range=(1,2))\n",
    "pipeline = Pipeline([\n",
    "    ('vect', cvt),\n",
    "#    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', AdaBoostClassifier())\n",
    "]) \n",
    "pipeline.fit(X_train, y_train)\n",
    "predicted = pipeline.predict(X_test)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report demonstrates that the classifier precisely tagged jobs that were not data science jobs - in 95% of cases, jobs tagged as not data science jobs were not data science jobs. Likewise, the classifier tagged a higher rate of total non-data science postings, nearly 96%. That said, the classifier performed very well predicting the minority class of data science jobs, guessing correctly 78% of the time and identifying 70% of cases. These results seem particularly impressive when reconsidering that I tagged the postings as data science jobs or not subjectively, based on a quick scan of job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      other       0.95      0.96      0.95       109\n",
      "     ds_job       0.78      0.70      0.74        20\n",
      "\n",
      "avg / total       0.92      0.92      0.92       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted, target_names=[\"other\", \"ds_job\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Predictors - Occupation\n",
    "\n",
    "Though boosted decision trees provided a better score, logistic regression coefficients derived from word counts once again provide insight about what differentiates the occupation groups. The strongest predictors of whether a job is a data science job are identical to those terms likewise predicting high salary. We also see the presence of data mining, predictive modeling, data visualization, and deep learning, among other terms, as predicting data science roles. Negatively predicting a data science role, as with income: requiring only a bachelor’s degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = cvt.fit_transform(scraped_postings['summary'])\n",
    "y = scraped_postings['ds_job']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine learning</th>\n",
       "      <td>0.722316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist</th>\n",
       "      <td>0.432207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big data</th>\n",
       "      <td>0.419141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science</th>\n",
       "      <td>0.330205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictive models</th>\n",
       "      <td>0.134650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data visualization</th>\n",
       "      <td>0.118815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictive modeling</th>\n",
       "      <td>0.104879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep learning</th>\n",
       "      <td>0.104829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning techniques</th>\n",
       "      <td>0.103479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data mining</th>\n",
       "      <td>0.100352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real time</th>\n",
       "      <td>0.091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning techniques</th>\n",
       "      <td>0.091576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance marketing</th>\n",
       "      <td>0.075128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative discipline</th>\n",
       "      <td>0.073246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm development</th>\n",
       "      <td>0.072297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 coef\n",
       "machine learning             0.722316\n",
       "data scientist               0.432207\n",
       "big data                     0.419141\n",
       "data science                 0.330205\n",
       "predictive models            0.134650\n",
       "data visualization           0.118815\n",
       "predictive modeling          0.104879\n",
       "deep learning                0.104829\n",
       "learning techniques          0.103479\n",
       "data mining                  0.100352\n",
       "real time                    0.091732\n",
       "machine learning techniques  0.091576\n",
       "insurance marketing          0.075128\n",
       "quantitative discipline      0.073246\n",
       "algorithm development        0.072297"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(cvt.get_feature_names())\n",
    "lr_coefs = pd.DataFrame({'coef':lr.coef_[0]},index=features)\n",
    "lr_coefs = lr_coefs.sort_values('coef',ascending=False)\n",
    "lr_coefs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication skills</th>\n",
       "      <td>-0.225888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education bachelor</th>\n",
       "      <td>-0.354551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type full time</th>\n",
       "      <td>-0.410733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type full</th>\n",
       "      <td>-0.410733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full time</th>\n",
       "      <td>-0.454437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          coef\n",
       "communication skills -0.225888\n",
       "education bachelor   -0.354551\n",
       "type full time       -0.410733\n",
       "type full            -0.410733\n",
       "full time            -0.454437"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coefs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterizing Job Postings by Occupation\n",
    "\n",
    "As above, I use term frequency to characterize data science jobs and data related jobs though the classifier performed better using word counts. The distinctions here are much clearer than that of income level. Data related (non Data Science) jobs in the sample commonly invoke marketing, clinical, and research applications. Software is likewise common but no specific tools or applications are listed. Data Science jobs, on the other hand, commonly invoke machine learning, analytics, modeling, python, and big data. I think the data science jobs, via these terms, offer a much stronger sense of coherence than the broader group of data related jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           9.189892\n",
       "development    6.979458\n",
       "marketing      6.885673\n",
       "skills         6.433163\n",
       "team           5.898329\n",
       "sales          5.884908\n",
       "clinical       5.803983\n",
       "management     5.725871\n",
       "ability        5.495082\n",
       "support        5.203179\n",
       "research       5.033285\n",
       "analysis       5.020574\n",
       "software       4.952255\n",
       "strong         4.815434\n",
       "systems        4.758234\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf for postings not tagged data science postings\n",
    "mask = scraped_postings['ds_job'] == 0\n",
    "tfidf = TfidfVectorizer(stop_words=english, ngram_range=(1,4))\n",
    "X_all = tfidf.fit_transform(scraped_postings.ix[mask,'summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                6.915183\n",
       "learning            3.029908\n",
       "machine             2.414281\n",
       "machine learning    2.390501\n",
       "science             1.982925\n",
       "skills              1.788962\n",
       "analysis            1.770923\n",
       "analytics           1.761157\n",
       "models              1.669913\n",
       "big                 1.576679\n",
       "python              1.516496\n",
       "data science        1.508542\n",
       "development         1.503688\n",
       "big data            1.501329\n",
       "statistical         1.455048\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf for postings not tagged data science postings\n",
    "mask = scraped_postings['ds_job'] == 1\n",
    "tfidf = TfidfVectorizer(stop_words=english, ngram_range=(1,4))\n",
    "X_all = tfidf.fit_transform(scraped_postings.ix[mask,'summary'])\n",
    "columns  =  np.array(tfidf.get_feature_names())\n",
    "\n",
    "freq_words = get_freq_words(X_all, columns)\n",
    "freq_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all. Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
